{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0a17859",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T11:43:15.738432Z",
     "iopub.status.busy": "2025-03-15T11:43:15.737904Z",
     "iopub.status.idle": "2025-03-15T11:43:24.262826Z",
     "shell.execute_reply": "2025-03-15T11:43:24.261576Z"
    },
    "papermill": {
     "duration": 8.535964,
     "end_time": "2025-03-15T11:43:24.264815",
     "exception": false,
     "start_time": "2025-03-15T11:43:15.728851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('mode.use_inf_as_na', False)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)  \n",
    "\n",
    "import catboost as cb\n",
    "\n",
    "from scipy.stats import gaussian_kde\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, \n",
    "    accuracy_score, \n",
    "    classification_report, \n",
    "\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold ,train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "308a23d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T11:43:24.280430Z",
     "iopub.status.busy": "2025-03-15T11:43:24.279853Z",
     "iopub.status.idle": "2025-03-15T11:43:24.291337Z",
     "shell.execute_reply": "2025-03-15T11:43:24.290102Z"
    },
    "papermill": {
     "duration": 0.021494,
     "end_time": "2025-03-15T11:43:24.293483",
     "exception": false,
     "start_time": "2025-03-15T11:43:24.271989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e18310c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T11:43:24.308292Z",
     "iopub.status.busy": "2025-03-15T11:43:24.307875Z",
     "iopub.status.idle": "2025-03-15T11:43:24.329225Z",
     "shell.execute_reply": "2025-03-15T11:43:24.328087Z"
    },
    "papermill": {
     "duration": 0.031284,
     "end_time": "2025-03-15T11:43:24.331564",
     "exception": false,
     "start_time": "2025-03-15T11:43:24.300280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class data_preprocess:\n",
    "    def __init__(self, data_train, data_test, target):\n",
    "        self.data_train = data_train\n",
    "        self.data_test = data_test\n",
    "        self.target = target\n",
    "        self.median_col = [\n",
    "            'pressure',\n",
    "            'maxtemp',\n",
    "            'temparature',\n",
    "            'mintemp',\n",
    "            'dewpoint'\n",
    "        ]\n",
    "        self.weird_col = [\n",
    "            'humidity',\n",
    "            'cloud',\n",
    "            'sunshine',\n",
    "            'windspeed'\n",
    "        ]\n",
    "        \n",
    "    def _reduce_col(self):\n",
    "        _cols = self.data_test.columns\n",
    "\n",
    "        mean_wind_tr = (self.data_train['winddirection'].mean()).round()\n",
    "        self.data_test['winddirection'].fillna(mean_wind_tr, inplace=True)\n",
    "\n",
    "        for col in _cols:\n",
    "            if self.data_train[col].dtype == 'int64':\n",
    "                self.data_train[col] = self.data_train[col].astype('int32')\n",
    "                self.data_test[col] = self.data_test[col].astype('int32')\n",
    "            \n",
    "            elif self.data_train[col].dtype == 'float64':\n",
    "                self.data_train[col] = self.data_train[col].astype('float32')\n",
    "                self.data_test[col] = self.data_test[col].astype('float32')\n",
    "\n",
    "    def _extra_features(self):\n",
    "        self.data_train['col_1'] = self.data_train['maxtemp'] - self.data_train['mintemp']\n",
    "        self.data_test['col_1'] = self.data_test['maxtemp'] - self.data_test['mintemp']\n",
    "\n",
    "        self.data_train['col_2'] = self.data_train['temparature'] - self.data_train['mintemp']\n",
    "        self.data_test['col_2'] = self.data_test['temparature'] - self.data_test['mintemp']\n",
    "\n",
    "        self.data_train['col_3'] = self.data_train['maxtemp'] - self.data_train['temparature']\n",
    "        self.data_test['col_3'] = self.data_train['maxtemp'] - self.data_test['temparature']\n",
    "\n",
    "        self.data_train['col_4'] = self.data_train['humidity'] - self.data_train['dewpoint']\n",
    "        self.data_test['col_4'] = self.data_test['humidity'] - self.data_test['dewpoint']\n",
    "\n",
    "        self.data_train['col_rad'] = np.deg2rad(self.data_train['winddirection'])\n",
    "        self.data_train['col_5'] = self.data_train['windspeed'] * np.sin(self.data_train['col_rad']*3.14 / 180)\n",
    "        self.data_train['col_6'] = self.data_train['windspeed'] * np.cos(self.data_train['col_rad']*3.14 / 180)\n",
    "        self.data_train.drop(columns=['col_rad'], inplace=True)\n",
    "        self.data_test['col_rad'] = np.deg2rad(self.data_test['winddirection'])\n",
    "        self.data_test['col_5'] = self.data_test['windspeed'] * np.sin(self.data_test['col_rad']*3.14 / 180)\n",
    "        self.data_test['col_6'] = self.data_test['windspeed'] * np.cos(self.data_test['col_rad']*3.14 / 180)\n",
    "        self.data_test.drop(columns=['col_rad'], inplace=True)\n",
    "\n",
    "        self.data_train['col_7'] = (\n",
    "            35.74 + \n",
    "            (0.6215 * self.data_train['temparature']) - \n",
    "            (35.75 * (self.data_train['winddirection']**0.16)) + \n",
    "            (0.4275 * self.data_train['temparature'] * (self.data_train['winddirection']**0.16))\n",
    "            )\n",
    "        \n",
    "        self.data_test['col_7'] = (\n",
    "            35.74 + \n",
    "            (0.6215 * self.data_test['temparature']) - \n",
    "            (35.75 * (self.data_test['winddirection']**0.16)) + \n",
    "            (0.4275 * self.data_test['temparature'] * (self.data_test['winddirection']**0.16))\n",
    "            )\n",
    "    \n",
    "    def _weird_features(self):\n",
    "        _cols = self.data_test.columns\n",
    "\n",
    "        data_filtered = self.data_train.copy()\n",
    "        data_filtered = data_filtered.loc[data_filtered['rainfall'] == 0]\n",
    "\n",
    "        for m_col in self.median_col:\n",
    "            f_name = f'median_diff_{m_col}'\n",
    "            val = data_filtered[m_col].mean()\n",
    "            self.data_train[f_name] = self.data_train[m_col] - val\n",
    "            self.data_test[f_name] = self.data_test[m_col] - val\n",
    "        \n",
    "        w_columns = []\n",
    "        for w_col in self.weird_col:\n",
    "            cat_val_1 = self.data_train[self.data_train[self.target] == 1][w_col]\n",
    "            cat_val_2 = self.data_train[self.data_train[self.target] == 0][w_col]\n",
    "            \n",
    "            kde_1 = gaussian_kde(cat_val_1)\n",
    "            kde_2 = gaussian_kde(cat_val_2)\n",
    "            \n",
    "            x_1 = np.linspace(min(cat_val_1), max(cat_val_1), 500)  \n",
    "            y_1 = kde_1(x_1)\n",
    "            max_val_in_1 = np.argmax(y_1)\n",
    "            max_val_1 = x_1[max_val_in_1]\n",
    "            \n",
    "            x_2 = np.linspace(min(cat_val_2), max(cat_val_2), 500)\n",
    "            y_2 = kde_2(x_2)\n",
    "            max_val_in_2 = np.argmax(y_2)\n",
    "            max_val_2 = x_2[max_val_in_2]\n",
    "            \n",
    "            mean_v = (max_val_1 + max_val_2) / 2\n",
    "           \n",
    "            col_name = f'cat_{w_col}'\n",
    "            w_columns.append(col_name)\n",
    "            self.data_train[col_name] = self.data_train[w_col].apply(lambda x: 1 if x >= mean_v else 0)\n",
    "            self.data_test[col_name] = self.data_test[w_col].apply(lambda x: 1 if x >= mean_v else 0)\n",
    "            \n",
    "        self.data_train['bit_col'] = self.data_train[w_columns].apply(lambda x: ''.join(x.astype(str)), axis=1)\n",
    "        self.data_test['bit_col'] = self.data_test[w_columns].apply(lambda x: ''.join(x.astype(str)), axis=1)\n",
    "        self.data_train['dec_col'] = self.data_train['bit_col'].apply(lambda x: int(x,2))\n",
    "        self.data_test['dec_col'] = self.data_test['bit_col'].apply(lambda x: int(x,2))\n",
    "        self.data_train.drop(columns=['bit_col'], inplace=True)\n",
    "        self.data_test.drop(columns=['bit_col'], inplace=True)\n",
    "\n",
    "    def _process(self):\n",
    "        self._reduce_col()\n",
    "        self._extra_features()\n",
    "        self._weird_features()\n",
    "\n",
    "        return self.data_train, self.data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4640415d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T11:43:24.346714Z",
     "iopub.status.busy": "2025-03-15T11:43:24.346367Z",
     "iopub.status.idle": "2025-03-15T11:43:24.364404Z",
     "shell.execute_reply": "2025-03-15T11:43:24.363232Z"
    },
    "papermill": {
     "duration": 0.027961,
     "end_time": "2025-03-15T11:43:24.366489",
     "exception": false,
     "start_time": "2025-03-15T11:43:24.338528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CatBoostModel:\n",
    "    def __init__(self, objective='Logloss', eval_metric='AUC', task_type = 'CPU', n_trials=100):\n",
    "        self.objective = objective  \n",
    "        self.eval_metric = eval_metric  \n",
    "        self.n_trials = n_trials\n",
    "        self.device_type = task_type\n",
    "        self.best_params = None\n",
    "        self.model = None\n",
    "        self.history = None\n",
    "        self.best_iteration = None\n",
    "\n",
    "    def objective_function(self, trial, X_train, y_train, X_val, y_val):\n",
    "        params = {\n",
    "            'objective': self.objective,  \n",
    "            'eval_metric': self.eval_metric,  \n",
    "            'loss_function': self.objective,  \n",
    "            'iterations': trial.suggest_int('iterations', 100, 1000),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1),\n",
    "            'depth': trial.suggest_int('depth', 3, 10),\n",
    "            'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-8, 1.0, log=True),\n",
    "            'random_seed': 42,\n",
    "            'task_type': self.device_type,\n",
    "            'verbose': False,\n",
    "            'early_stopping_rounds': 50  \n",
    "        }\n",
    "\n",
    "        model = cb.CatBoostClassifier(**params) \n",
    "        model.fit(X_train, y_train,\n",
    "                  eval_set=[(X_val, y_val)],\n",
    "                  verbose=False)\n",
    "\n",
    "        preds_proba = model.predict_proba(X_val)[:, 1]  \n",
    "        score = roc_auc_score(y_val, preds_proba)\n",
    "        return score\n",
    "\n",
    "    def optimize_hyperparameters(self, X_train, y_train, X_val, y_val):\n",
    "        study = optuna.create_study(direction='maximize') \n",
    "        study.optimize(lambda trial: self.objective_function(trial, X_train, y_train, X_val, y_val),\n",
    "                       n_trials=self.n_trials)\n",
    "\n",
    "        self.best_params = study.best_params\n",
    "        print(f\"Best parameters: {self.best_params}\")\n",
    "\n",
    "    def train(self, X_train, y_train, X_val=None, y_val=None):\n",
    "        if self.best_params is None:\n",
    "            raise ValueError('You must optimize hyperparameters first.')\n",
    "\n",
    "        params = self.best_params.copy()\n",
    "        params['objective'] = self.objective \n",
    "        params['eval_metric'] = self.eval_metric  \n",
    "        params['loss_function'] = self.objective  \n",
    "        params['random_seed'] = 42\n",
    "        params['verbose'] = False\n",
    "\n",
    "        self.model = cb.CatBoostClassifier(**params)\n",
    "\n",
    "        if X_val is not None and y_val is not None:\n",
    "            self.model.fit(X_train, y_train,\n",
    "                           eval_set=[(X_val, y_val)],\n",
    "                           verbose=False,\n",
    "                           plot=False)\n",
    "            self.history = self.model.get_evals_result()\n",
    "            self.best_iteration = self.model.get_best_iteration()\n",
    "        else:\n",
    "            self.model.fit(X_train, y_train, verbose=False)\n",
    "            self.history = None\n",
    "            self.best_iteration = None\n",
    "\n",
    "    def plot_training_history(self):\n",
    "        if self.history is None:\n",
    "            print('Training history is not available. Please train with validation data.')\n",
    "            return\n",
    "\n",
    "        print('Educational background structure:', self.history.keys())\n",
    "\n",
    "        metric = self.eval_metric\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(self.history['validation'][metric], label=f'Validation ({metric})')\n",
    "\n",
    "        if self.best_iteration is not None:\n",
    "            plt.axvline(self.best_iteration, color='red', linestyle='--', label=f'Best Iteration ({self.best_iteration})')\n",
    "        plt.xlabel('Trails')\n",
    "        plt.ylabel(metric.upper())\n",
    "        plt.title(f'CatBoost Training History ({metric})')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.model is None:\n",
    "            raise ValueError('You must train the model first.')\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def predict_proba(self, X): \n",
    "        if self.model is None:\n",
    "            raise ValueError('You must train the model first.')\n",
    "        return self.model.predict_proba(X)\n",
    "\n",
    "    def save_model(self, filepath):\n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump(self.model, f)\n",
    "        print(f\"Model saved to: {filepath}\")\n",
    "\n",
    "    def load_model(self, filepath):\n",
    "        if not os.path.exists(filepath):\n",
    "            raise FileNotFoundError(f\"Model file not found: {filepath}\")\n",
    "\n",
    "        with open(filepath, 'rb') as f:\n",
    "            self.model = pickle.load(f)\n",
    "        print(f\"Model loaded from: {filepath}\")\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"You must train the model first.\")\n",
    "\n",
    "        preds = self.predict(X_test)\n",
    "        preds_proba = self.predict_proba(X_test)[:, 1] \n",
    "\n",
    "        accuracy = accuracy_score(y_test, preds)\n",
    "        report = classification_report(y_test, preds)\n",
    "        auc = roc_auc_score(y_test, preds_proba)\n",
    "\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        print(\"Classification Report:\\n\", report)\n",
    "        print(f\"AUC: {auc}\")\n",
    "        return auc, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "321d7ef6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T11:43:24.381575Z",
     "iopub.status.busy": "2025-03-15T11:43:24.381198Z",
     "iopub.status.idle": "2025-03-15T11:43:24.394536Z",
     "shell.execute_reply": "2025-03-15T11:43:24.393241Z"
    },
    "papermill": {
     "duration": 0.022772,
     "end_time": "2025-03-15T11:43:24.396392",
     "exception": false,
     "start_time": "2025-03-15T11:43:24.373620",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LogisticRegressionModel:\n",
    "    def __init__(self, n_trials=100):\n",
    "        self.n_trials = n_trials\n",
    "        self.best_params = None\n",
    "        self.model = None\n",
    "        self.history = None\n",
    "        self.best_iteration = None\n",
    "        self.scaler = None  \n",
    "\n",
    "    def objective_function(self, trial, X_train, y_train, X_val, y_val):\n",
    "        C = trial.suggest_float(\"C\", 1e-5, 1e5, log=True) \n",
    "        solver = trial.suggest_categorical(\"solver\", [\"liblinear\", \"saga\", \"newton-cg\"])  \n",
    "        \n",
    "        if solver == \"newton-cg\":\n",
    "          penalty = \"l2\"\n",
    "        else:\n",
    "          penalty = trial.suggest_categorical(\"penalty\", [\"l1\", \"l2\"])  \n",
    "\n",
    "        model = LogisticRegression(C=C, solver=solver, penalty=penalty, random_state=42, max_iter=100)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "\n",
    "        return roc_auc  \n",
    "\n",
    "    def optimize_hyperparameters(self, X_train, y_train, X_val, y_val):\n",
    "        study = optuna.create_study(direction='maximize') \n",
    "        study.optimize(lambda trial: self.objective_function(trial, X_train, y_train, X_val, y_val),\n",
    "                       n_trials=self.n_trials)\n",
    "\n",
    "        self.best_params = study.best_params\n",
    "        print(f\"Best parameters: {self.best_params}\")\n",
    "\n",
    "    def train(self, X_train, y_train, X_val=None, y_val=None):\n",
    "        if self.best_params is None:\n",
    "            raise ValueError('You must optimize hyperparameters first.')\n",
    "\n",
    "        self.model = LogisticRegression(**self.best_params, random_state=42, max_iter=100)\n",
    "\n",
    "        self.scaler = StandardScaler()\n",
    "        X_train = self.scaler.fit_transform(X_train)\n",
    "        self.model.fit(X_train, y_train)\n",
    "        self.history = None\n",
    "        self.best_iteration = None\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.model is None:\n",
    "            raise ValueError('You must train the model first.')\n",
    "        X = self.scaler.transform(X)\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        if self.model is None:\n",
    "            raise ValueError('You must train the model first.')\n",
    "        X = self.scaler.transform(X)\n",
    "        return self.model.predict_proba(X)\n",
    "\n",
    "    def save_model(self, filepath):\n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump(self, f)  \n",
    "        print(f\"Model saved to: {filepath}\")\n",
    "\n",
    "    def load_model(self, filepath):\n",
    "        if not os.path.exists(filepath):\n",
    "            raise FileNotFoundError(f\"Model file not found: {filepath}\")\n",
    "\n",
    "        with open(filepath, 'rb') as f:\n",
    "            loaded = pickle.load(f)\n",
    "            self.model = loaded.model\n",
    "            self.scaler = loaded.scaler \n",
    "        print(f\"Model loaded from: {filepath}\")\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"You must train the model first.\")\n",
    "\n",
    "        X_test = self.scaler.transform(X_test)\n",
    "        y_pred = self.predict(X_test)\n",
    "        y_pred_proba = self.predict_proba(X_test)[:, 1]  \n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        print(f\"ROC AUC: {roc_auc}\")\n",
    "        return roc_auc, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb26fd9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T11:43:24.411291Z",
     "iopub.status.busy": "2025-03-15T11:43:24.410767Z",
     "iopub.status.idle": "2025-03-15T11:43:24.417881Z",
     "shell.execute_reply": "2025-03-15T11:43:24.416730Z"
    },
    "papermill": {
     "duration": 0.016434,
     "end_time": "2025-03-15T11:43:24.419687",
     "exception": false,
     "start_time": "2025-03-15T11:43:24.403253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def stratified_kfold_cross_validation(X, y, model, n_splits=5):  \n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)  \n",
    "    auc_scores = []\n",
    "    acc_scores = []\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(X, y)):\n",
    "        print(f\"Fold {fold + 1}/{n_splits}\")  \n",
    "\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "        model.optimize_hyperparameters(X_train, y_train, X_val, y_val) \n",
    "        model.train(X_train, y_train, X_val, y_val)\n",
    "        #model.plot_training_history()\n",
    "        auc, acc = model.evaluate(X_val, y_val) \n",
    "        auc_scores.append(auc)\n",
    "        acc_scores.append(acc)\n",
    "        model.save_model(f\"/kaggle/working/catboost_model_{fold + 1}.pkl\")\n",
    "\n",
    "    print(f\"AUC Mean: {np.mean(auc_scores)}\")\n",
    "    print(f\"AUC Scores: {auc_scores}\")\n",
    "    \n",
    "    max_index, max_value = max(enumerate(auc_scores), key=lambda x: x[1])\n",
    "    return max_index, acc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93f25460",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T11:43:24.434304Z",
     "iopub.status.busy": "2025-03-15T11:43:24.433917Z",
     "iopub.status.idle": "2025-03-15T11:43:24.440646Z",
     "shell.execute_reply": "2025-03-15T11:43:24.439568Z"
    },
    "papermill": {
     "duration": 0.016026,
     "end_time": "2025-03-15T11:43:24.442464",
     "exception": false,
     "start_time": "2025-03-15T11:43:24.426438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def stratified_kfold_cross_validation_2(X, y, model, n_splits=5):  \n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)  \n",
    "    auc_scores = []\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(X, y)):\n",
    "        print(f\"Fold {fold + 1}/{n_splits}\")  \n",
    "\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "        model.optimize_hyperparameters(X_train, y_train, X_val, y_val)\n",
    "        model.train(X_train, y_train)\n",
    "        auc, acc = model.evaluate(X_val, y_val)\n",
    "        model.save_model(f'/kaggle/working/logistic_regression_model_{fold + 1}.pkl')\n",
    "        auc_scores.append(auc)\n",
    "\n",
    "    print(f\"AUC Mean: {np.mean(auc_scores)}\")\n",
    "    print(f\"AUC Scores: {auc_scores}\")\n",
    "    \n",
    "    max_index, max_value = max(enumerate(auc_scores), key=lambda x: x[1])\n",
    "    return max_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "467b8fba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T11:43:24.457422Z",
     "iopub.status.busy": "2025-03-15T11:43:24.456995Z",
     "iopub.status.idle": "2025-03-15T11:43:24.490120Z",
     "shell.execute_reply": "2025-03-15T11:43:24.488967Z"
    },
    "papermill": {
     "duration": 0.042712,
     "end_time": "2025-03-15T11:43:24.492206",
     "exception": false,
     "start_time": "2025-03-15T11:43:24.449494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/kaggle/input/playground-series-s5e3/train.csv')\n",
    "df_test = pd.read_csv('/kaggle/input/playground-series-s5e3/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31ef7e4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T11:43:24.507348Z",
     "iopub.status.busy": "2025-03-15T11:43:24.506930Z",
     "iopub.status.idle": "2025-03-15T11:43:24.524765Z",
     "shell.execute_reply": "2025-03-15T11:43:24.523693Z"
    },
    "papermill": {
     "duration": 0.027376,
     "end_time": "2025-03-15T11:43:24.526609",
     "exception": false,
     "start_time": "2025-03-15T11:43:24.499233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns=['id', 'day'])\n",
    "df_test_id = df_test['id']\n",
    "df_test = df_test.drop(columns=['id', 'day',])\n",
    "df_train_y = df_train['rainfall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8630d96b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T11:43:24.541484Z",
     "iopub.status.busy": "2025-03-15T11:43:24.541093Z",
     "iopub.status.idle": "2025-03-15T11:43:24.892429Z",
     "shell.execute_reply": "2025-03-15T11:43:24.891305Z"
    },
    "papermill": {
     "duration": 0.361436,
     "end_time": "2025-03-15T11:43:24.894763",
     "exception": false,
     "start_time": "2025-03-15T11:43:24.533327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train, df_test = data_preprocess(df_train, df_test,'rainfall')._process()\n",
    "df_train = df_train.drop(columns=['rainfall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc37dfec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T11:43:24.918993Z",
     "iopub.status.busy": "2025-03-15T11:43:24.918590Z",
     "iopub.status.idle": "2025-03-15T11:43:24.926964Z",
     "shell.execute_reply": "2025-03-15T11:43:24.925850Z"
    },
    "papermill": {
     "duration": 0.02257,
     "end_time": "2025-03-15T11:43:24.928884",
     "exception": false,
     "start_time": "2025-03-15T11:43:24.906314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cpy_tr = df_train.copy()\n",
    "cat_lin_tr = cpy_tr.drop(columns=['dec_col'])\n",
    "cpy_te = df_test.copy()\n",
    "cat_lin_te = cpy_te.drop(columns=['dec_col'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ce8865b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T11:43:24.943532Z",
     "iopub.status.busy": "2025-03-15T11:43:24.943159Z",
     "iopub.status.idle": "2025-03-15T11:43:24.951204Z",
     "shell.execute_reply": "2025-03-15T11:43:24.950066Z"
    },
    "papermill": {
     "duration": 0.017663,
     "end_time": "2025-03-15T11:43:24.953330",
     "exception": false,
     "start_time": "2025-03-15T11:43:24.935667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlp_tr = df_train.drop(columns=['cat_humidity', 'cat_cloud', 'cat_sunshine', 'cat_windspeed'])\n",
    "mlp_te = df_test.drop(columns=['cat_humidity', 'cat_cloud', 'cat_sunshine', 'cat_windspeed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "061cdd70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T11:43:24.975740Z",
     "iopub.status.busy": "2025-03-15T11:43:24.975372Z",
     "iopub.status.idle": "2025-03-15T11:43:25.001677Z",
     "shell.execute_reply": "2025-03-15T11:43:25.000537Z"
    },
    "papermill": {
     "duration": 0.039311,
     "end_time": "2025-03-15T11:43:25.003936",
     "exception": false,
     "start_time": "2025-03-15T11:43:24.964625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "cat_lin_tr = scaler.fit_transform(cat_lin_tr)\n",
    "cat_lin_te = scaler.transform(cat_lin_te)\n",
    "\n",
    "df_train_y = pd.Series(df_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d73876b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T11:43:25.027804Z",
     "iopub.status.busy": "2025-03-15T11:43:25.027388Z",
     "iopub.status.idle": "2025-03-15T12:06:07.587177Z",
     "shell.execute_reply": "2025-03-15T12:06:07.586041Z"
    },
    "papermill": {
     "duration": 1362.5738,
     "end_time": "2025-03-15T12:06:07.588991",
     "exception": false,
     "start_time": "2025-03-15T11:43:25.015191",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/10\n",
      "Best parameters: {'iterations': 779, 'learning_rate': 0.0926217132260029, 'depth': 5, 'l2_leaf_reg': 2.3286900206102864e-07}\n",
      "Accuracy: 0.8904109589041096\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.76      0.77        54\n",
      "           1       0.92      0.93      0.93       165\n",
      "\n",
      "    accuracy                           0.89       219\n",
      "   macro avg       0.86      0.85      0.85       219\n",
      "weighted avg       0.89      0.89      0.89       219\n",
      "\n",
      "AUC: 0.915151515151515\n",
      "Model saved to: /kaggle/working/catboost_model_1.pkl\n",
      "Fold 2/10\n",
      "Best parameters: {'iterations': 854, 'learning_rate': 0.07953061196893552, 'depth': 4, 'l2_leaf_reg': 4.644879907704908e-07}\n",
      "Accuracy: 0.9269406392694064\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.80      0.84        54\n",
      "           1       0.94      0.97      0.95       165\n",
      "\n",
      "    accuracy                           0.93       219\n",
      "   macro avg       0.92      0.88      0.90       219\n",
      "weighted avg       0.93      0.93      0.93       219\n",
      "\n",
      "AUC: 0.9643097643097643\n",
      "Model saved to: /kaggle/working/catboost_model_2.pkl\n",
      "Fold 3/10\n",
      "Best parameters: {'iterations': 819, 'learning_rate': 0.08350984196775513, 'depth': 10, 'l2_leaf_reg': 4.974836390521704e-07}\n",
      "Accuracy: 0.867579908675799\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.74      0.73        54\n",
      "           1       0.91      0.91      0.91       165\n",
      "\n",
      "    accuracy                           0.87       219\n",
      "   macro avg       0.82      0.82      0.82       219\n",
      "weighted avg       0.87      0.87      0.87       219\n",
      "\n",
      "AUC: 0.9041526374859707\n",
      "Model saved to: /kaggle/working/catboost_model_3.pkl\n",
      "Fold 4/10\n",
      "Best parameters: {'iterations': 796, 'learning_rate': 0.04169313016976942, 'depth': 9, 'l2_leaf_reg': 8.491675885046374e-08}\n",
      "Accuracy: 0.8584474885844748\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.59      0.67        54\n",
      "           1       0.88      0.95      0.91       165\n",
      "\n",
      "    accuracy                           0.86       219\n",
      "   macro avg       0.83      0.77      0.79       219\n",
      "weighted avg       0.85      0.86      0.85       219\n",
      "\n",
      "AUC: 0.8479236812570146\n",
      "Model saved to: /kaggle/working/catboost_model_4.pkl\n",
      "Fold 5/10\n",
      "Best parameters: {'iterations': 398, 'learning_rate': 0.06050538576920702, 'depth': 6, 'l2_leaf_reg': 2.8879007794864407e-06}\n",
      "Accuracy: 0.8493150684931506\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.57      0.65        54\n",
      "           1       0.87      0.94      0.90       165\n",
      "\n",
      "    accuracy                           0.85       219\n",
      "   macro avg       0.81      0.76      0.78       219\n",
      "weighted avg       0.84      0.85      0.84       219\n",
      "\n",
      "AUC: 0.8932659932659933\n",
      "Model saved to: /kaggle/working/catboost_model_5.pkl\n",
      "Fold 6/10\n",
      "Best parameters: {'iterations': 748, 'learning_rate': 0.07333565625790361, 'depth': 4, 'l2_leaf_reg': 2.3092478003280633e-05}\n",
      "Accuracy: 0.8447488584474886\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.59      0.65        54\n",
      "           1       0.87      0.93      0.90       165\n",
      "\n",
      "    accuracy                           0.84       219\n",
      "   macro avg       0.80      0.76      0.78       219\n",
      "weighted avg       0.84      0.84      0.84       219\n",
      "\n",
      "AUC: 0.8983164983164984\n",
      "Model saved to: /kaggle/working/catboost_model_6.pkl\n",
      "Fold 7/10\n",
      "Best parameters: {'iterations': 214, 'learning_rate': 0.05119867471737995, 'depth': 3, 'l2_leaf_reg': 1.9032272359541973e-05}\n",
      "Accuracy: 0.863013698630137\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.63      0.69        54\n",
      "           1       0.89      0.94      0.91       165\n",
      "\n",
      "    accuracy                           0.86       219\n",
      "   macro avg       0.83      0.78      0.80       219\n",
      "weighted avg       0.86      0.86      0.86       219\n",
      "\n",
      "AUC: 0.9260381593714928\n",
      "Model saved to: /kaggle/working/catboost_model_7.pkl\n",
      "Fold 8/10\n",
      "Best parameters: {'iterations': 144, 'learning_rate': 0.0996020237120552, 'depth': 3, 'l2_leaf_reg': 0.08322819361605577}\n",
      "Accuracy: 0.8493150684931506\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.69      0.69        54\n",
      "           1       0.90      0.90      0.90       165\n",
      "\n",
      "    accuracy                           0.85       219\n",
      "   macro avg       0.80      0.79      0.80       219\n",
      "weighted avg       0.85      0.85      0.85       219\n",
      "\n",
      "AUC: 0.9241301907968574\n",
      "Model saved to: /kaggle/working/catboost_model_8.pkl\n",
      "Fold 9/10\n",
      "Best parameters: {'iterations': 890, 'learning_rate': 0.053443980724352864, 'depth': 9, 'l2_leaf_reg': 0.061294685778343655}\n",
      "Accuracy: 0.8858447488584474\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.70      0.75        54\n",
      "           1       0.91      0.95      0.93       165\n",
      "\n",
      "    accuracy                           0.89       219\n",
      "   macro avg       0.86      0.82      0.84       219\n",
      "weighted avg       0.88      0.89      0.88       219\n",
      "\n",
      "AUC: 0.9410774410774411\n",
      "Model saved to: /kaggle/working/catboost_model_9.pkl\n",
      "Fold 10/10\n",
      "Best parameters: {'iterations': 258, 'learning_rate': 0.07294705940077424, 'depth': 8, 'l2_leaf_reg': 0.5141088750989754}\n",
      "Accuracy: 0.8858447488584474\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.69      0.75        54\n",
      "           1       0.90      0.95      0.93       165\n",
      "\n",
      "    accuracy                           0.89       219\n",
      "   macro avg       0.86      0.82      0.84       219\n",
      "weighted avg       0.88      0.89      0.88       219\n",
      "\n",
      "AUC: 0.902020202020202\n",
      "Model saved to: /kaggle/working/catboost_model_10.pkl\n",
      "AUC Mean: 0.9116386083052749\n",
      "AUC Scores: [0.915151515151515, 0.9643097643097643, 0.9041526374859707, 0.8479236812570146, 0.8932659932659933, 0.8983164983164984, 0.9260381593714928, 0.9241301907968574, 0.9410774410774411, 0.902020202020202]\n",
      "CPU times: user 1h 9min 20s, sys: 6min 16s, total: 1h 15min 36s\n",
      "Wall time: 22min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "catboost_model = CatBoostModel(objective='Logloss', eval_metric='AUC', task_type='CPU', n_trials=200)\n",
    "auc_num, max_acc = stratified_kfold_cross_validation(cat_lin_tr, df_train_y, catboost_model, n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "005fd157",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T12:06:07.605730Z",
     "iopub.status.busy": "2025-03-15T12:06:07.605404Z",
     "iopub.status.idle": "2025-03-15T12:07:11.190484Z",
     "shell.execute_reply": "2025-03-15T12:07:11.189172Z"
    },
    "papermill": {
     "duration": 63.595508,
     "end_time": "2025-03-15T12:07:11.192342",
     "exception": false,
     "start_time": "2025-03-15T12:06:07.596834",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/10\n",
      "Best parameters: {'C': 0.015308432409689344, 'solver': 'newton-cg'}\n",
      "ROC AUC: 0.8900112233445566\n",
      "Model saved to: /kaggle/working/logistic_regression_model_1.pkl\n",
      "Fold 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.11545233596164559, 'solver': 'liblinear', 'penalty': 'l1'}\n",
      "ROC AUC: 0.9567901234567902\n",
      "Model saved to: /kaggle/working/logistic_regression_model_2.pkl\n",
      "Fold 3/10\n",
      "Best parameters: {'C': 0.001107249883834535, 'solver': 'newton-cg'}\n",
      "ROC AUC: 0.8905723905723906\n",
      "Model saved to: /kaggle/working/logistic_regression_model_3.pkl\n",
      "Fold 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.045784371669716585, 'solver': 'saga', 'penalty': 'l1'}\n",
      "ROC AUC: 0.8327721661054995\n",
      "Model saved to: /kaggle/working/logistic_regression_model_4.pkl\n",
      "Fold 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 2.1870080509660963, 'solver': 'liblinear', 'penalty': 'l2'}\n",
      "ROC AUC: 0.8823793490460157\n",
      "Model saved to: /kaggle/working/logistic_regression_model_5.pkl\n",
      "Fold 6/10\n",
      "Best parameters: {'C': 0.014467440059857969, 'solver': 'saga', 'penalty': 'l2'}\n",
      "ROC AUC: 0.8901234567901234\n",
      "Model saved to: /kaggle/working/logistic_regression_model_6.pkl\n",
      "Fold 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 79050.56355812351, 'solver': 'newton-cg'}\n",
      "ROC AUC: 0.9093153759820426\n",
      "Model saved to: /kaggle/working/logistic_regression_model_7.pkl\n",
      "Fold 8/10\n",
      "Best parameters: {'C': 99989.38156412655, 'solver': 'newton-cg'}\n",
      "ROC AUC: 0.9161616161616162\n",
      "Model saved to: /kaggle/working/logistic_regression_model_8.pkl\n",
      "Fold 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.03256812575145203, 'solver': 'liblinear', 'penalty': 'l1'}\n",
      "ROC AUC: 0.9151515151515152\n",
      "Model saved to: /kaggle/working/logistic_regression_model_9.pkl\n",
      "Fold 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.0036080974835774166, 'solver': 'newton-cg'}\n",
      "ROC AUC: 0.8884399551066218\n",
      "Model saved to: /kaggle/working/logistic_regression_model_10.pkl\n",
      "AUC Mean: 0.8971717171717172\n",
      "AUC Scores: [0.8900112233445566, 0.9567901234567902, 0.8905723905723906, 0.8327721661054995, 0.8823793490460157, 0.8901234567901234, 0.9093153759820426, 0.9161616161616162, 0.9151515151515152, 0.8884399551066218]\n",
      "CPU times: user 1min 22s, sys: 481 ms, total: 1min 22s\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegressionModel(n_trials=200)\n",
    "auc_num_li = stratified_kfold_cross_validation_2(cat_lin_tr, df_train_y, model, n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5494236c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T12:07:11.213426Z",
     "iopub.status.busy": "2025-03-15T12:07:11.213003Z",
     "iopub.status.idle": "2025-03-15T12:07:11.226265Z",
     "shell.execute_reply": "2025-03-15T12:07:11.224988Z"
    },
    "papermill": {
     "duration": 0.025435,
     "end_time": "2025-03-15T12:07:11.227921",
     "exception": false,
     "start_time": "2025-03-15T12:07:11.202486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from: /kaggle/working/catboost_model_2.pkl\n"
     ]
    }
   ],
   "source": [
    "loaded_cat_model = CatBoostModel()\n",
    "cat_name = f'/kaggle/working/catboost_model_{auc_num + 1}.pkl'\n",
    "loaded_cat_model.load_model(cat_name)\n",
    "predictions_cat = loaded_cat_model.predict(cat_lin_te)\n",
    "probabilities_cat = loaded_cat_model.predict_proba(cat_lin_te)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32929910",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T12:07:11.249889Z",
     "iopub.status.busy": "2025-03-15T12:07:11.249578Z",
     "iopub.status.idle": "2025-03-15T12:07:11.256784Z",
     "shell.execute_reply": "2025-03-15T12:07:11.255280Z"
    },
    "papermill": {
     "duration": 0.020192,
     "end_time": "2025-03-15T12:07:11.258692",
     "exception": false,
     "start_time": "2025-03-15T12:07:11.238500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from: /kaggle/working/logistic_regression_model_2.pkl\n"
     ]
    }
   ],
   "source": [
    "loaded_model_lin = LogisticRegressionModel()\n",
    "loaded_model_lin.load_model(f'/kaggle/working/logistic_regression_model_{auc_num_li + 1}.pkl')\n",
    "probabilities_lin = loaded_model_lin.predict_proba(cat_lin_te)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3186c658",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T12:07:11.281285Z",
     "iopub.status.busy": "2025-03-15T12:07:11.280893Z",
     "iopub.status.idle": "2025-03-15T12:07:11.287588Z",
     "shell.execute_reply": "2025-03-15T12:07:11.286438Z"
    },
    "papermill": {
     "duration": 0.020854,
     "end_time": "2025-03-15T12:07:11.289590",
     "exception": false,
     "start_time": "2025-03-15T12:07:11.268736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_rate=0.5):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)  \n",
    "        self.fc2 = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)  \n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71053ce4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T12:07:11.312098Z",
     "iopub.status.busy": "2025-03-15T12:07:11.311739Z",
     "iopub.status.idle": "2025-03-15T12:07:11.326020Z",
     "shell.execute_reply": "2025-03-15T12:07:11.324967Z"
    },
    "papermill": {
     "duration": 0.027607,
     "end_time": "2025-03-15T12:07:11.327759",
     "exception": false,
     "start_time": "2025-03-15T12:07:11.300152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial, X_train, X_val, y_train, y_val):\n",
    "    lr = trial.suggest_loguniform('lr', 1e-5, 1e-2)\n",
    "    hidden_size = trial.suggest_int('hidden_size', 20, 100)\n",
    "    dropout_rate = trial.suggest_uniform('dropout_rate', 0.0, 0.5)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "    num_epochs = trial.suggest_int('num_epochs', 10, 200)\n",
    "\n",
    "    X_train = torch.tensor(X_train.to_numpy(), dtype=torch.float32)\n",
    "    X_val = torch.tensor(X_val.to_numpy(), dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train.to_numpy(), dtype=torch.float32)\n",
    "    y_val = torch.tensor(y_val.to_numpy(), dtype=torch.float32)\n",
    "    \n",
    "\n",
    "\n",
    "    class MLP(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, dropout_rate=0.5):\n",
    "            super(MLP, self).__init__()\n",
    "            self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "            self.relu = nn.ReLU()\n",
    "            self.dropout = nn.Dropout(dropout_rate)  \n",
    "            self.fc2 = nn.Linear(hidden_size, 1)\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        def forward(self, x):\n",
    "            out = self.fc1(x)\n",
    "            out = self.relu(out)\n",
    "            out = self.dropout(out)  \n",
    "            out = self.fc2(out)\n",
    "            out = self.sigmoid(out)\n",
    "            return out\n",
    "    \n",
    "    input_size = X_train.shape[1]\n",
    "    model = MLP(input_size, hidden_size, dropout_rate)\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.unsqueeze(1)) \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) \n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()  \n",
    "\n",
    "            predicted = (outputs > 0.5).float()  \n",
    "            correct_predictions += (predicted == labels.unsqueeze(1)).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "            #if (i + 1) % 10 == 0:\n",
    "            #    print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "            #          .format(epoch + 1, num_epochs, i + 1, len(train_loader), loss.item()))\n",
    "\n",
    "        epoch_loss /= len(train_loader)\n",
    "        epoch_accuracy = correct_predictions / total_samples\n",
    "\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accuracies.append(epoch_accuracy)\n",
    "\n",
    "        #print('Epoch [{}/{}], Train Loss: {:.4f}, Train Accuracy: {:.4f}'\n",
    "        #      .format(epoch + 1, num_epochs, epoch_loss, epoch_accuracy))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_val)\n",
    "        predicted_probs = outputs.cpu().numpy() \n",
    "        auc = roc_auc_score(y_val.cpu().numpy(), predicted_probs) \n",
    "        #print('Test AUC: {:.4f}'.format(auc))\n",
    "    '''\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_accuracies, label='Train Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    '''\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5792f910",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T12:07:11.348917Z",
     "iopub.status.busy": "2025-03-15T12:07:11.348580Z",
     "iopub.status.idle": "2025-03-15T12:07:11.354439Z",
     "shell.execute_reply": "2025-03-15T12:07:11.353387Z"
    },
    "papermill": {
     "duration": 0.018629,
     "end_time": "2025-03-15T12:07:11.356219",
     "exception": false,
     "start_time": "2025-03-15T12:07:11.337590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_optuna_mlp(X_train, X_val, y_train, y_val, n_trials=200):\n",
    "    def lambda_objective(trial):\n",
    "        return objective(trial, X_train, X_val, y_train, y_val)\n",
    "        \n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(lambda_objective, n_trials=n_trials)\n",
    "\n",
    "    print(\"Best Trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a3e8183",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T12:07:11.378617Z",
     "iopub.status.busy": "2025-03-15T12:07:11.378208Z",
     "iopub.status.idle": "2025-03-15T12:07:11.386351Z",
     "shell.execute_reply": "2025-03-15T12:07:11.385279Z"
    },
    "papermill": {
     "duration": 0.021744,
     "end_time": "2025-03-15T12:07:11.388151",
     "exception": false,
     "start_time": "2025-03-15T12:07:11.366407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(mlp_tr, df_train_y, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae74d564",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T12:07:11.409205Z",
     "iopub.status.busy": "2025-03-15T12:07:11.408772Z",
     "iopub.status.idle": "2025-03-15T12:52:23.857006Z",
     "shell.execute_reply": "2025-03-15T12:52:23.855841Z"
    },
    "papermill": {
     "duration": 2712.469797,
     "end_time": "2025-03-15T12:52:23.867929",
     "exception": false,
     "start_time": "2025-03-15T12:07:11.398132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Trial:\n",
      "  Value: 0.8788230025552541\n",
      "  Params: \n",
      "    lr: 0.0011085555225503467\n",
      "    hidden_size: 69\n",
      "    dropout_rate: 0.08113795388780992\n",
      "    batch_size: 32\n",
      "    num_epochs: 126\n"
     ]
    }
   ],
   "source": [
    "best_params_mlp = run_optuna_mlp(X_train, X_val, y_train, y_val, n_trials=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ec03666",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T12:52:23.890637Z",
     "iopub.status.busy": "2025-03-15T12:52:23.890035Z",
     "iopub.status.idle": "2025-03-15T12:52:38.572776Z",
     "shell.execute_reply": "2025-03-15T12:52:38.571705Z"
    },
    "papermill": {
     "duration": 14.696346,
     "end_time": "2025-03-15T12:52:38.574789",
     "exception": false,
     "start_time": "2025-03-15T12:52:23.878443",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/126], Step [10/55], Loss: 18.7500\n",
      "Epoch [1/126], Step [20/55], Loss: 15.8481\n",
      "Epoch [1/126], Step [30/55], Loss: 31.2500\n",
      "Epoch [1/126], Step [40/55], Loss: 12.5000\n",
      "Epoch [1/126], Step [50/55], Loss: 28.1250\n",
      "Epoch [1/126], Train Loss: 22.5760, Train Accuracy: 0.7437\n",
      "Epoch [2/126], Step [10/55], Loss: 21.8750\n",
      "Epoch [2/126], Step [20/55], Loss: 13.6474\n",
      "Epoch [2/126], Step [30/55], Loss: 7.0909\n",
      "Epoch [2/126], Step [40/55], Loss: 19.6926\n",
      "Epoch [2/126], Step [50/55], Loss: 22.3087\n",
      "Epoch [2/126], Train Loss: 17.2489, Train Accuracy: 0.7009\n",
      "Epoch [3/126], Step [10/55], Loss: 8.1791\n",
      "Epoch [3/126], Step [20/55], Loss: 9.0024\n",
      "Epoch [3/126], Step [30/55], Loss: 14.2375\n",
      "Epoch [3/126], Step [40/55], Loss: 8.6198\n",
      "Epoch [3/126], Step [50/55], Loss: 13.3741\n",
      "Epoch [3/126], Train Loss: 8.3764, Train Accuracy: 0.7078\n",
      "Epoch [4/126], Step [10/55], Loss: 9.4134\n",
      "Epoch [4/126], Step [20/55], Loss: 4.2673\n",
      "Epoch [4/126], Step [30/55], Loss: 1.2066\n",
      "Epoch [4/126], Step [40/55], Loss: 4.9406\n",
      "Epoch [4/126], Step [50/55], Loss: 0.9133\n",
      "Epoch [4/126], Train Loss: 4.6489, Train Accuracy: 0.7323\n",
      "Epoch [5/126], Step [10/55], Loss: 2.3643\n",
      "Epoch [5/126], Step [20/55], Loss: 4.1786\n",
      "Epoch [5/126], Step [30/55], Loss: 4.6269\n",
      "Epoch [5/126], Step [40/55], Loss: 0.0364\n",
      "Epoch [5/126], Step [50/55], Loss: 1.3369\n",
      "Epoch [5/126], Train Loss: 3.0746, Train Accuracy: 0.7688\n",
      "Epoch [6/126], Step [10/55], Loss: 1.0159\n",
      "Epoch [6/126], Step [20/55], Loss: 0.8705\n",
      "Epoch [6/126], Step [30/55], Loss: 0.7095\n",
      "Epoch [6/126], Step [40/55], Loss: 1.0735\n",
      "Epoch [6/126], Step [50/55], Loss: 3.7888\n",
      "Epoch [6/126], Train Loss: 2.1119, Train Accuracy: 0.8134\n",
      "Epoch [7/126], Step [10/55], Loss: 1.2648\n",
      "Epoch [7/126], Step [20/55], Loss: 0.6422\n",
      "Epoch [7/126], Step [30/55], Loss: 1.0029\n",
      "Epoch [7/126], Step [40/55], Loss: 0.7556\n",
      "Epoch [7/126], Step [50/55], Loss: 1.6794\n",
      "Epoch [7/126], Train Loss: 0.8364, Train Accuracy: 0.8105\n",
      "Epoch [8/126], Step [10/55], Loss: 0.3847\n",
      "Epoch [8/126], Step [20/55], Loss: 0.4761\n",
      "Epoch [8/126], Step [30/55], Loss: 0.6967\n",
      "Epoch [8/126], Step [40/55], Loss: 0.3621\n",
      "Epoch [8/126], Step [50/55], Loss: 1.0016\n",
      "Epoch [8/126], Train Loss: 0.6302, Train Accuracy: 0.7985\n",
      "Epoch [9/126], Step [10/55], Loss: 0.3787\n",
      "Epoch [9/126], Step [20/55], Loss: 0.1696\n",
      "Epoch [9/126], Step [30/55], Loss: 0.9840\n",
      "Epoch [9/126], Step [40/55], Loss: 0.3269\n",
      "Epoch [9/126], Step [50/55], Loss: 0.4529\n",
      "Epoch [9/126], Train Loss: 0.4998, Train Accuracy: 0.8191\n",
      "Epoch [10/126], Step [10/55], Loss: 0.3157\n",
      "Epoch [10/126], Step [20/55], Loss: 0.3499\n",
      "Epoch [10/126], Step [30/55], Loss: 0.3927\n",
      "Epoch [10/126], Step [40/55], Loss: 0.2378\n",
      "Epoch [10/126], Step [50/55], Loss: 0.3450\n",
      "Epoch [10/126], Train Loss: 0.3943, Train Accuracy: 0.8408\n",
      "Epoch [11/126], Step [10/55], Loss: 0.3640\n",
      "Epoch [11/126], Step [20/55], Loss: 0.6186\n",
      "Epoch [11/126], Step [30/55], Loss: 0.2359\n",
      "Epoch [11/126], Step [40/55], Loss: 0.4150\n",
      "Epoch [11/126], Step [50/55], Loss: 0.1952\n",
      "Epoch [11/126], Train Loss: 0.3528, Train Accuracy: 0.8590\n",
      "Epoch [12/126], Step [10/55], Loss: 0.2431\n",
      "Epoch [12/126], Step [20/55], Loss: 0.5538\n",
      "Epoch [12/126], Step [30/55], Loss: 0.4188\n",
      "Epoch [12/126], Step [40/55], Loss: 0.4991\n",
      "Epoch [12/126], Step [50/55], Loss: 0.1723\n",
      "Epoch [12/126], Train Loss: 0.4139, Train Accuracy: 0.8288\n",
      "Epoch [13/126], Step [10/55], Loss: 0.3208\n",
      "Epoch [13/126], Step [20/55], Loss: 0.3814\n",
      "Epoch [13/126], Step [30/55], Loss: 0.4284\n",
      "Epoch [13/126], Step [40/55], Loss: 0.2320\n",
      "Epoch [13/126], Step [50/55], Loss: 0.2207\n",
      "Epoch [13/126], Train Loss: 0.3533, Train Accuracy: 0.8590\n",
      "Epoch [14/126], Step [10/55], Loss: 0.5131\n",
      "Epoch [14/126], Step [20/55], Loss: 0.3614\n",
      "Epoch [14/126], Step [30/55], Loss: 0.3226\n",
      "Epoch [14/126], Step [40/55], Loss: 0.3513\n",
      "Epoch [14/126], Step [50/55], Loss: 0.4689\n",
      "Epoch [14/126], Train Loss: 0.3620, Train Accuracy: 0.8510\n",
      "Epoch [15/126], Step [10/55], Loss: 0.4161\n",
      "Epoch [15/126], Step [20/55], Loss: 0.2826\n",
      "Epoch [15/126], Step [30/55], Loss: 0.2187\n",
      "Epoch [15/126], Step [40/55], Loss: 0.6069\n",
      "Epoch [15/126], Step [50/55], Loss: 0.3505\n",
      "Epoch [15/126], Train Loss: 0.3522, Train Accuracy: 0.8562\n",
      "Epoch [16/126], Step [10/55], Loss: 0.3211\n",
      "Epoch [16/126], Step [20/55], Loss: 0.3778\n",
      "Epoch [16/126], Step [30/55], Loss: 0.4634\n",
      "Epoch [16/126], Step [40/55], Loss: 0.4175\n",
      "Epoch [16/126], Step [50/55], Loss: 0.2752\n",
      "Epoch [16/126], Train Loss: 0.3692, Train Accuracy: 0.8579\n",
      "Epoch [17/126], Step [10/55], Loss: 0.2776\n",
      "Epoch [17/126], Step [20/55], Loss: 0.4019\n",
      "Epoch [17/126], Step [30/55], Loss: 0.4096\n",
      "Epoch [17/126], Step [40/55], Loss: 0.4850\n",
      "Epoch [17/126], Step [50/55], Loss: 0.2201\n",
      "Epoch [17/126], Train Loss: 0.3632, Train Accuracy: 0.8533\n",
      "Epoch [18/126], Step [10/55], Loss: 0.7969\n",
      "Epoch [18/126], Step [20/55], Loss: 0.2824\n",
      "Epoch [18/126], Step [30/55], Loss: 0.6375\n",
      "Epoch [18/126], Step [40/55], Loss: 0.2973\n",
      "Epoch [18/126], Step [50/55], Loss: 0.3570\n",
      "Epoch [18/126], Train Loss: 0.3568, Train Accuracy: 0.8533\n",
      "Epoch [19/126], Step [10/55], Loss: 0.2776\n",
      "Epoch [19/126], Step [20/55], Loss: 0.4447\n",
      "Epoch [19/126], Step [30/55], Loss: 0.5822\n",
      "Epoch [19/126], Step [40/55], Loss: 0.3900\n",
      "Epoch [19/126], Step [50/55], Loss: 0.4602\n",
      "Epoch [19/126], Train Loss: 0.3470, Train Accuracy: 0.8596\n",
      "Epoch [20/126], Step [10/55], Loss: 0.1846\n",
      "Epoch [20/126], Step [20/55], Loss: 0.2850\n",
      "Epoch [20/126], Step [30/55], Loss: 0.2842\n",
      "Epoch [20/126], Step [40/55], Loss: 0.1620\n",
      "Epoch [20/126], Step [50/55], Loss: 0.4014\n",
      "Epoch [20/126], Train Loss: 0.3518, Train Accuracy: 0.8573\n",
      "Epoch [21/126], Step [10/55], Loss: 0.3354\n",
      "Epoch [21/126], Step [20/55], Loss: 0.5493\n",
      "Epoch [21/126], Step [30/55], Loss: 0.4212\n",
      "Epoch [21/126], Step [40/55], Loss: 0.4540\n",
      "Epoch [21/126], Step [50/55], Loss: 0.1726\n",
      "Epoch [21/126], Train Loss: 0.3399, Train Accuracy: 0.8613\n",
      "Epoch [22/126], Step [10/55], Loss: 0.2974\n",
      "Epoch [22/126], Step [20/55], Loss: 0.2122\n",
      "Epoch [22/126], Step [30/55], Loss: 0.4213\n",
      "Epoch [22/126], Step [40/55], Loss: 0.4744\n",
      "Epoch [22/126], Step [50/55], Loss: 0.4293\n",
      "Epoch [22/126], Train Loss: 0.3494, Train Accuracy: 0.8653\n",
      "Epoch [23/126], Step [10/55], Loss: 0.4109\n",
      "Epoch [23/126], Step [20/55], Loss: 0.4126\n",
      "Epoch [23/126], Step [30/55], Loss: 0.2903\n",
      "Epoch [23/126], Step [40/55], Loss: 0.3932\n",
      "Epoch [23/126], Step [50/55], Loss: 0.1027\n",
      "Epoch [23/126], Train Loss: 0.3478, Train Accuracy: 0.8687\n",
      "Epoch [24/126], Step [10/55], Loss: 0.2341\n",
      "Epoch [24/126], Step [20/55], Loss: 0.3147\n",
      "Epoch [24/126], Step [30/55], Loss: 0.3961\n",
      "Epoch [24/126], Step [40/55], Loss: 0.3324\n",
      "Epoch [24/126], Step [50/55], Loss: 0.3939\n",
      "Epoch [24/126], Train Loss: 0.3446, Train Accuracy: 0.8619\n",
      "Epoch [25/126], Step [10/55], Loss: 0.2733\n",
      "Epoch [25/126], Step [20/55], Loss: 0.2519\n",
      "Epoch [25/126], Step [30/55], Loss: 0.4585\n",
      "Epoch [25/126], Step [40/55], Loss: 0.4410\n",
      "Epoch [25/126], Step [50/55], Loss: 0.3557\n",
      "Epoch [25/126], Train Loss: 0.3438, Train Accuracy: 0.8602\n",
      "Epoch [26/126], Step [10/55], Loss: 0.3481\n",
      "Epoch [26/126], Step [20/55], Loss: 0.3069\n",
      "Epoch [26/126], Step [30/55], Loss: 0.1698\n",
      "Epoch [26/126], Step [40/55], Loss: 0.7496\n",
      "Epoch [26/126], Step [50/55], Loss: 0.4501\n",
      "Epoch [26/126], Train Loss: 0.3631, Train Accuracy: 0.8539\n",
      "Epoch [27/126], Step [10/55], Loss: 0.4386\n",
      "Epoch [27/126], Step [20/55], Loss: 0.1456\n",
      "Epoch [27/126], Step [30/55], Loss: 0.3079\n",
      "Epoch [27/126], Step [40/55], Loss: 0.4873\n",
      "Epoch [27/126], Step [50/55], Loss: 0.4866\n",
      "Epoch [27/126], Train Loss: 0.3431, Train Accuracy: 0.8590\n",
      "Epoch [28/126], Step [10/55], Loss: 0.3816\n",
      "Epoch [28/126], Step [20/55], Loss: 0.2648\n",
      "Epoch [28/126], Step [30/55], Loss: 0.3327\n",
      "Epoch [28/126], Step [40/55], Loss: 0.3896\n",
      "Epoch [28/126], Step [50/55], Loss: 0.4580\n",
      "Epoch [28/126], Train Loss: 0.3380, Train Accuracy: 0.8602\n",
      "Epoch [29/126], Step [10/55], Loss: 0.3758\n",
      "Epoch [29/126], Step [20/55], Loss: 0.3586\n",
      "Epoch [29/126], Step [30/55], Loss: 0.4649\n",
      "Epoch [29/126], Step [40/55], Loss: 0.3582\n",
      "Epoch [29/126], Step [50/55], Loss: 0.3635\n",
      "Epoch [29/126], Train Loss: 0.3432, Train Accuracy: 0.8613\n",
      "Epoch [30/126], Step [10/55], Loss: 0.2650\n",
      "Epoch [30/126], Step [20/55], Loss: 0.4163\n",
      "Epoch [30/126], Step [30/55], Loss: 0.4323\n",
      "Epoch [30/126], Step [40/55], Loss: 0.3446\n",
      "Epoch [30/126], Step [50/55], Loss: 0.2689\n",
      "Epoch [30/126], Train Loss: 0.3371, Train Accuracy: 0.8647\n",
      "Epoch [31/126], Step [10/55], Loss: 0.3606\n",
      "Epoch [31/126], Step [20/55], Loss: 0.3923\n",
      "Epoch [31/126], Step [30/55], Loss: 0.3850\n",
      "Epoch [31/126], Step [40/55], Loss: 0.2336\n",
      "Epoch [31/126], Step [50/55], Loss: 0.4744\n",
      "Epoch [31/126], Train Loss: 0.3382, Train Accuracy: 0.8619\n",
      "Epoch [32/126], Step [10/55], Loss: 0.3482\n",
      "Epoch [32/126], Step [20/55], Loss: 0.3062\n",
      "Epoch [32/126], Step [30/55], Loss: 0.4413\n",
      "Epoch [32/126], Step [40/55], Loss: 0.3528\n",
      "Epoch [32/126], Step [50/55], Loss: 0.3197\n",
      "Epoch [32/126], Train Loss: 0.3294, Train Accuracy: 0.8750\n",
      "Epoch [33/126], Step [10/55], Loss: 0.4807\n",
      "Epoch [33/126], Step [20/55], Loss: 0.2076\n",
      "Epoch [33/126], Step [30/55], Loss: 0.4283\n",
      "Epoch [33/126], Step [40/55], Loss: 0.1552\n",
      "Epoch [33/126], Step [50/55], Loss: 0.2635\n",
      "Epoch [33/126], Train Loss: 0.3303, Train Accuracy: 0.8636\n",
      "Epoch [34/126], Step [10/55], Loss: 0.3235\n",
      "Epoch [34/126], Step [20/55], Loss: 0.3531\n",
      "Epoch [34/126], Step [30/55], Loss: 0.4278\n",
      "Epoch [34/126], Step [40/55], Loss: 0.3526\n",
      "Epoch [34/126], Step [50/55], Loss: 0.4176\n",
      "Epoch [34/126], Train Loss: 0.3494, Train Accuracy: 0.8602\n",
      "Epoch [35/126], Step [10/55], Loss: 0.2547\n",
      "Epoch [35/126], Step [20/55], Loss: 0.3864\n",
      "Epoch [35/126], Step [30/55], Loss: 0.4281\n",
      "Epoch [35/126], Step [40/55], Loss: 0.3438\n",
      "Epoch [35/126], Step [50/55], Loss: 0.2630\n",
      "Epoch [35/126], Train Loss: 0.3507, Train Accuracy: 0.8613\n",
      "Epoch [36/126], Step [10/55], Loss: 0.2376\n",
      "Epoch [36/126], Step [20/55], Loss: 0.2757\n",
      "Epoch [36/126], Step [30/55], Loss: 0.3017\n",
      "Epoch [36/126], Step [40/55], Loss: 0.2891\n",
      "Epoch [36/126], Step [50/55], Loss: 0.4568\n",
      "Epoch [36/126], Train Loss: 0.3352, Train Accuracy: 0.8647\n",
      "Epoch [37/126], Step [10/55], Loss: 0.2320\n",
      "Epoch [37/126], Step [20/55], Loss: 0.3464\n",
      "Epoch [37/126], Step [30/55], Loss: 0.2709\n",
      "Epoch [37/126], Step [40/55], Loss: 0.1771\n",
      "Epoch [37/126], Step [50/55], Loss: 0.3586\n",
      "Epoch [37/126], Train Loss: 0.3307, Train Accuracy: 0.8607\n",
      "Epoch [38/126], Step [10/55], Loss: 0.5500\n",
      "Epoch [38/126], Step [20/55], Loss: 0.3992\n",
      "Epoch [38/126], Step [30/55], Loss: 0.2098\n",
      "Epoch [38/126], Step [40/55], Loss: 0.3560\n",
      "Epoch [38/126], Step [50/55], Loss: 0.2182\n",
      "Epoch [38/126], Train Loss: 0.3353, Train Accuracy: 0.8624\n",
      "Epoch [39/126], Step [10/55], Loss: 0.2503\n",
      "Epoch [39/126], Step [20/55], Loss: 0.5755\n",
      "Epoch [39/126], Step [30/55], Loss: 0.2575\n",
      "Epoch [39/126], Step [40/55], Loss: 0.1781\n",
      "Epoch [39/126], Step [50/55], Loss: 0.2771\n",
      "Epoch [39/126], Train Loss: 0.3303, Train Accuracy: 0.8682\n",
      "Epoch [40/126], Step [10/55], Loss: 0.4693\n",
      "Epoch [40/126], Step [20/55], Loss: 0.2444\n",
      "Epoch [40/126], Step [30/55], Loss: 0.1850\n",
      "Epoch [40/126], Step [40/55], Loss: 0.2931\n",
      "Epoch [40/126], Step [50/55], Loss: 0.3991\n",
      "Epoch [40/126], Train Loss: 0.3273, Train Accuracy: 0.8676\n",
      "Epoch [41/126], Step [10/55], Loss: 0.2682\n",
      "Epoch [41/126], Step [20/55], Loss: 0.3520\n",
      "Epoch [41/126], Step [30/55], Loss: 0.1833\n",
      "Epoch [41/126], Step [40/55], Loss: 0.3252\n",
      "Epoch [41/126], Step [50/55], Loss: 0.2002\n",
      "Epoch [41/126], Train Loss: 0.3255, Train Accuracy: 0.8704\n",
      "Epoch [42/126], Step [10/55], Loss: 0.1866\n",
      "Epoch [42/126], Step [20/55], Loss: 0.1494\n",
      "Epoch [42/126], Step [30/55], Loss: 0.4528\n",
      "Epoch [42/126], Step [40/55], Loss: 0.3449\n",
      "Epoch [42/126], Step [50/55], Loss: 0.3059\n",
      "Epoch [42/126], Train Loss: 0.3270, Train Accuracy: 0.8721\n",
      "Epoch [43/126], Step [10/55], Loss: 0.4252\n",
      "Epoch [43/126], Step [20/55], Loss: 0.3193\n",
      "Epoch [43/126], Step [30/55], Loss: 0.3860\n",
      "Epoch [43/126], Step [40/55], Loss: 0.3687\n",
      "Epoch [43/126], Step [50/55], Loss: 0.0936\n",
      "Epoch [43/126], Train Loss: 0.3282, Train Accuracy: 0.8699\n",
      "Epoch [44/126], Step [10/55], Loss: 0.1151\n",
      "Epoch [44/126], Step [20/55], Loss: 0.4073\n",
      "Epoch [44/126], Step [30/55], Loss: 0.2453\n",
      "Epoch [44/126], Step [40/55], Loss: 0.2924\n",
      "Epoch [44/126], Step [50/55], Loss: 0.1889\n",
      "Epoch [44/126], Train Loss: 0.3342, Train Accuracy: 0.8664\n",
      "Epoch [45/126], Step [10/55], Loss: 0.2591\n",
      "Epoch [45/126], Step [20/55], Loss: 0.2827\n",
      "Epoch [45/126], Step [30/55], Loss: 0.3002\n",
      "Epoch [45/126], Step [40/55], Loss: 0.3676\n",
      "Epoch [45/126], Step [50/55], Loss: 0.3188\n",
      "Epoch [45/126], Train Loss: 0.3179, Train Accuracy: 0.8721\n",
      "Epoch [46/126], Step [10/55], Loss: 0.3138\n",
      "Epoch [46/126], Step [20/55], Loss: 0.2526\n",
      "Epoch [46/126], Step [30/55], Loss: 0.4953\n",
      "Epoch [46/126], Step [40/55], Loss: 0.6608\n",
      "Epoch [46/126], Step [50/55], Loss: 0.5228\n",
      "Epoch [46/126], Train Loss: 0.3214, Train Accuracy: 0.8682\n",
      "Epoch [47/126], Step [10/55], Loss: 0.2181\n",
      "Epoch [47/126], Step [20/55], Loss: 0.6033\n",
      "Epoch [47/126], Step [30/55], Loss: 0.3697\n",
      "Epoch [47/126], Step [40/55], Loss: 0.4330\n",
      "Epoch [47/126], Step [50/55], Loss: 0.4017\n",
      "Epoch [47/126], Train Loss: 0.3276, Train Accuracy: 0.8653\n",
      "Epoch [48/126], Step [10/55], Loss: 0.4037\n",
      "Epoch [48/126], Step [20/55], Loss: 0.3181\n",
      "Epoch [48/126], Step [30/55], Loss: 0.2605\n",
      "Epoch [48/126], Step [40/55], Loss: 0.4294\n",
      "Epoch [48/126], Step [50/55], Loss: 0.2225\n",
      "Epoch [48/126], Train Loss: 0.3284, Train Accuracy: 0.8670\n",
      "Epoch [49/126], Step [10/55], Loss: 0.1808\n",
      "Epoch [49/126], Step [20/55], Loss: 0.2577\n",
      "Epoch [49/126], Step [30/55], Loss: 0.4048\n",
      "Epoch [49/126], Step [40/55], Loss: 0.1549\n",
      "Epoch [49/126], Step [50/55], Loss: 0.3291\n",
      "Epoch [49/126], Train Loss: 0.3219, Train Accuracy: 0.8687\n",
      "Epoch [50/126], Step [10/55], Loss: 0.2096\n",
      "Epoch [50/126], Step [20/55], Loss: 0.3062\n",
      "Epoch [50/126], Step [30/55], Loss: 0.1844\n",
      "Epoch [50/126], Step [40/55], Loss: 0.4678\n",
      "Epoch [50/126], Step [50/55], Loss: 0.4208\n",
      "Epoch [50/126], Train Loss: 0.3223, Train Accuracy: 0.8727\n",
      "Epoch [51/126], Step [10/55], Loss: 0.5807\n",
      "Epoch [51/126], Step [20/55], Loss: 0.3079\n",
      "Epoch [51/126], Step [30/55], Loss: 0.5015\n",
      "Epoch [51/126], Step [40/55], Loss: 0.2608\n",
      "Epoch [51/126], Step [50/55], Loss: 0.4781\n",
      "Epoch [51/126], Train Loss: 0.3311, Train Accuracy: 0.8727\n",
      "Epoch [52/126], Step [10/55], Loss: 0.3084\n",
      "Epoch [52/126], Step [20/55], Loss: 0.2356\n",
      "Epoch [52/126], Step [30/55], Loss: 0.4247\n",
      "Epoch [52/126], Step [40/55], Loss: 0.3356\n",
      "Epoch [52/126], Step [50/55], Loss: 0.2006\n",
      "Epoch [52/126], Train Loss: 0.3276, Train Accuracy: 0.8779\n",
      "Epoch [53/126], Step [10/55], Loss: 0.5774\n",
      "Epoch [53/126], Step [20/55], Loss: 0.1492\n",
      "Epoch [53/126], Step [30/55], Loss: 0.1989\n",
      "Epoch [53/126], Step [40/55], Loss: 0.2935\n",
      "Epoch [53/126], Step [50/55], Loss: 0.4878\n",
      "Epoch [53/126], Train Loss: 0.3362, Train Accuracy: 0.8687\n",
      "Epoch [54/126], Step [10/55], Loss: 0.2121\n",
      "Epoch [54/126], Step [20/55], Loss: 0.2433\n",
      "Epoch [54/126], Step [30/55], Loss: 0.1529\n",
      "Epoch [54/126], Step [40/55], Loss: 0.1577\n",
      "Epoch [54/126], Step [50/55], Loss: 0.2144\n",
      "Epoch [54/126], Train Loss: 0.3195, Train Accuracy: 0.8716\n",
      "Epoch [55/126], Step [10/55], Loss: 0.2287\n",
      "Epoch [55/126], Step [20/55], Loss: 0.2178\n",
      "Epoch [55/126], Step [30/55], Loss: 0.2277\n",
      "Epoch [55/126], Step [40/55], Loss: 0.2996\n",
      "Epoch [55/126], Step [50/55], Loss: 0.2249\n",
      "Epoch [55/126], Train Loss: 0.3240, Train Accuracy: 0.8733\n",
      "Epoch [56/126], Step [10/55], Loss: 0.2839\n",
      "Epoch [56/126], Step [20/55], Loss: 0.3089\n",
      "Epoch [56/126], Step [30/55], Loss: 0.2703\n",
      "Epoch [56/126], Step [40/55], Loss: 0.3416\n",
      "Epoch [56/126], Step [50/55], Loss: 0.3636\n",
      "Epoch [56/126], Train Loss: 0.3292, Train Accuracy: 0.8710\n",
      "Epoch [57/126], Step [10/55], Loss: 0.3308\n",
      "Epoch [57/126], Step [20/55], Loss: 0.2904\n",
      "Epoch [57/126], Step [30/55], Loss: 0.2736\n",
      "Epoch [57/126], Step [40/55], Loss: 0.3209\n",
      "Epoch [57/126], Step [50/55], Loss: 0.2825\n",
      "Epoch [57/126], Train Loss: 0.3291, Train Accuracy: 0.8733\n",
      "Epoch [58/126], Step [10/55], Loss: 0.5398\n",
      "Epoch [58/126], Step [20/55], Loss: 0.1643\n",
      "Epoch [58/126], Step [30/55], Loss: 0.2788\n",
      "Epoch [58/126], Step [40/55], Loss: 0.4268\n",
      "Epoch [58/126], Step [50/55], Loss: 0.3133\n",
      "Epoch [58/126], Train Loss: 0.3273, Train Accuracy: 0.8664\n",
      "Epoch [59/126], Step [10/55], Loss: 0.4289\n",
      "Epoch [59/126], Step [20/55], Loss: 0.5580\n",
      "Epoch [59/126], Step [30/55], Loss: 0.2719\n",
      "Epoch [59/126], Step [40/55], Loss: 0.2496\n",
      "Epoch [59/126], Step [50/55], Loss: 0.2229\n",
      "Epoch [59/126], Train Loss: 0.3264, Train Accuracy: 0.8664\n",
      "Epoch [60/126], Step [10/55], Loss: 0.4592\n",
      "Epoch [60/126], Step [20/55], Loss: 0.2951\n",
      "Epoch [60/126], Step [30/55], Loss: 0.1501\n",
      "Epoch [60/126], Step [40/55], Loss: 0.3892\n",
      "Epoch [60/126], Step [50/55], Loss: 0.3381\n",
      "Epoch [60/126], Train Loss: 0.3290, Train Accuracy: 0.8733\n",
      "Epoch [61/126], Step [10/55], Loss: 0.3872\n",
      "Epoch [61/126], Step [20/55], Loss: 0.4220\n",
      "Epoch [61/126], Step [30/55], Loss: 0.3557\n",
      "Epoch [61/126], Step [40/55], Loss: 0.3055\n",
      "Epoch [61/126], Step [50/55], Loss: 0.3648\n",
      "Epoch [61/126], Train Loss: 0.3182, Train Accuracy: 0.8699\n",
      "Epoch [62/126], Step [10/55], Loss: 0.2293\n",
      "Epoch [62/126], Step [20/55], Loss: 0.3336\n",
      "Epoch [62/126], Step [30/55], Loss: 0.1935\n",
      "Epoch [62/126], Step [40/55], Loss: 0.2374\n",
      "Epoch [62/126], Step [50/55], Loss: 0.2874\n",
      "Epoch [62/126], Train Loss: 0.3224, Train Accuracy: 0.8693\n",
      "Epoch [63/126], Step [10/55], Loss: 0.1959\n",
      "Epoch [63/126], Step [20/55], Loss: 0.2077\n",
      "Epoch [63/126], Step [30/55], Loss: 0.3371\n",
      "Epoch [63/126], Step [40/55], Loss: 0.4109\n",
      "Epoch [63/126], Step [50/55], Loss: 0.1971\n",
      "Epoch [63/126], Train Loss: 0.3163, Train Accuracy: 0.8756\n",
      "Epoch [64/126], Step [10/55], Loss: 0.2111\n",
      "Epoch [64/126], Step [20/55], Loss: 0.2337\n",
      "Epoch [64/126], Step [30/55], Loss: 0.5926\n",
      "Epoch [64/126], Step [40/55], Loss: 0.2235\n",
      "Epoch [64/126], Step [50/55], Loss: 0.4722\n",
      "Epoch [64/126], Train Loss: 0.3213, Train Accuracy: 0.8756\n",
      "Epoch [65/126], Step [10/55], Loss: 0.3009\n",
      "Epoch [65/126], Step [20/55], Loss: 0.3955\n",
      "Epoch [65/126], Step [30/55], Loss: 0.3584\n",
      "Epoch [65/126], Step [40/55], Loss: 0.3627\n",
      "Epoch [65/126], Step [50/55], Loss: 0.2046\n",
      "Epoch [65/126], Train Loss: 0.3296, Train Accuracy: 0.8682\n",
      "Epoch [66/126], Step [10/55], Loss: 0.1309\n",
      "Epoch [66/126], Step [20/55], Loss: 0.2464\n",
      "Epoch [66/126], Step [30/55], Loss: 0.2317\n",
      "Epoch [66/126], Step [40/55], Loss: 0.2593\n",
      "Epoch [66/126], Step [50/55], Loss: 0.3936\n",
      "Epoch [66/126], Train Loss: 0.3254, Train Accuracy: 0.8733\n",
      "Epoch [67/126], Step [10/55], Loss: 0.3134\n",
      "Epoch [67/126], Step [20/55], Loss: 0.2551\n",
      "Epoch [67/126], Step [30/55], Loss: 0.6274\n",
      "Epoch [67/126], Step [40/55], Loss: 0.3192\n",
      "Epoch [67/126], Step [50/55], Loss: 0.5742\n",
      "Epoch [67/126], Train Loss: 0.3218, Train Accuracy: 0.8733\n",
      "Epoch [68/126], Step [10/55], Loss: 0.2878\n",
      "Epoch [68/126], Step [20/55], Loss: 0.3935\n",
      "Epoch [68/126], Step [30/55], Loss: 0.3461\n",
      "Epoch [68/126], Step [40/55], Loss: 0.1376\n",
      "Epoch [68/126], Step [50/55], Loss: 0.1034\n",
      "Epoch [68/126], Train Loss: 0.3272, Train Accuracy: 0.8682\n",
      "Epoch [69/126], Step [10/55], Loss: 0.3483\n",
      "Epoch [69/126], Step [20/55], Loss: 0.6366\n",
      "Epoch [69/126], Step [30/55], Loss: 0.4106\n",
      "Epoch [69/126], Step [40/55], Loss: 0.3167\n",
      "Epoch [69/126], Step [50/55], Loss: 0.2770\n",
      "Epoch [69/126], Train Loss: 0.3220, Train Accuracy: 0.8670\n",
      "Epoch [70/126], Step [10/55], Loss: 0.2243\n",
      "Epoch [70/126], Step [20/55], Loss: 0.2501\n",
      "Epoch [70/126], Step [30/55], Loss: 0.1758\n",
      "Epoch [70/126], Step [40/55], Loss: 0.4517\n",
      "Epoch [70/126], Step [50/55], Loss: 0.3056\n",
      "Epoch [70/126], Train Loss: 0.3228, Train Accuracy: 0.8739\n",
      "Epoch [71/126], Step [10/55], Loss: 0.3450\n",
      "Epoch [71/126], Step [20/55], Loss: 0.2630\n",
      "Epoch [71/126], Step [30/55], Loss: 0.4132\n",
      "Epoch [71/126], Step [40/55], Loss: 0.3176\n",
      "Epoch [71/126], Step [50/55], Loss: 0.1674\n",
      "Epoch [71/126], Train Loss: 0.3172, Train Accuracy: 0.8721\n",
      "Epoch [72/126], Step [10/55], Loss: 0.3405\n",
      "Epoch [72/126], Step [20/55], Loss: 0.4809\n",
      "Epoch [72/126], Step [30/55], Loss: 0.1906\n",
      "Epoch [72/126], Step [40/55], Loss: 0.1454\n",
      "Epoch [72/126], Step [50/55], Loss: 0.3246\n",
      "Epoch [72/126], Train Loss: 0.3257, Train Accuracy: 0.8750\n",
      "Epoch [73/126], Step [10/55], Loss: 0.2624\n",
      "Epoch [73/126], Step [20/55], Loss: 0.2663\n",
      "Epoch [73/126], Step [30/55], Loss: 0.4220\n",
      "Epoch [73/126], Step [40/55], Loss: 0.4859\n",
      "Epoch [73/126], Step [50/55], Loss: 0.3942\n",
      "Epoch [73/126], Train Loss: 0.3234, Train Accuracy: 0.8693\n",
      "Epoch [74/126], Step [10/55], Loss: 0.2443\n",
      "Epoch [74/126], Step [20/55], Loss: 0.1804\n",
      "Epoch [74/126], Step [30/55], Loss: 0.2479\n",
      "Epoch [74/126], Step [40/55], Loss: 0.4802\n",
      "Epoch [74/126], Step [50/55], Loss: 0.3173\n",
      "Epoch [74/126], Train Loss: 0.3245, Train Accuracy: 0.8710\n",
      "Epoch [75/126], Step [10/55], Loss: 0.6016\n",
      "Epoch [75/126], Step [20/55], Loss: 0.4043\n",
      "Epoch [75/126], Step [30/55], Loss: 0.3163\n",
      "Epoch [75/126], Step [40/55], Loss: 0.4383\n",
      "Epoch [75/126], Step [50/55], Loss: 0.2057\n",
      "Epoch [75/126], Train Loss: 0.3229, Train Accuracy: 0.8739\n",
      "Epoch [76/126], Step [10/55], Loss: 0.4481\n",
      "Epoch [76/126], Step [20/55], Loss: 0.1535\n",
      "Epoch [76/126], Step [30/55], Loss: 0.3098\n",
      "Epoch [76/126], Step [40/55], Loss: 0.2967\n",
      "Epoch [76/126], Step [50/55], Loss: 0.3058\n",
      "Epoch [76/126], Train Loss: 0.3296, Train Accuracy: 0.8721\n",
      "Epoch [77/126], Step [10/55], Loss: 0.2346\n",
      "Epoch [77/126], Step [20/55], Loss: 0.5881\n",
      "Epoch [77/126], Step [30/55], Loss: 0.4125\n",
      "Epoch [77/126], Step [40/55], Loss: 0.2085\n",
      "Epoch [77/126], Step [50/55], Loss: 0.4146\n",
      "Epoch [77/126], Train Loss: 0.3266, Train Accuracy: 0.8704\n",
      "Epoch [78/126], Step [10/55], Loss: 0.3368\n",
      "Epoch [78/126], Step [20/55], Loss: 0.3003\n",
      "Epoch [78/126], Step [30/55], Loss: 0.4474\n",
      "Epoch [78/126], Step [40/55], Loss: 0.2165\n",
      "Epoch [78/126], Step [50/55], Loss: 0.5320\n",
      "Epoch [78/126], Train Loss: 0.3228, Train Accuracy: 0.8733\n",
      "Epoch [79/126], Step [10/55], Loss: 0.2505\n",
      "Epoch [79/126], Step [20/55], Loss: 0.5446\n",
      "Epoch [79/126], Step [30/55], Loss: 0.4081\n",
      "Epoch [79/126], Step [40/55], Loss: 0.3798\n",
      "Epoch [79/126], Step [50/55], Loss: 0.4223\n",
      "Epoch [79/126], Train Loss: 0.3226, Train Accuracy: 0.8739\n",
      "Epoch [80/126], Step [10/55], Loss: 0.2976\n",
      "Epoch [80/126], Step [20/55], Loss: 0.2998\n",
      "Epoch [80/126], Step [30/55], Loss: 0.2532\n",
      "Epoch [80/126], Step [40/55], Loss: 0.6585\n",
      "Epoch [80/126], Step [50/55], Loss: 0.2336\n",
      "Epoch [80/126], Train Loss: 0.3246, Train Accuracy: 0.8784\n",
      "Epoch [81/126], Step [10/55], Loss: 0.2998\n",
      "Epoch [81/126], Step [20/55], Loss: 0.3344\n",
      "Epoch [81/126], Step [30/55], Loss: 0.3005\n",
      "Epoch [81/126], Step [40/55], Loss: 0.1662\n",
      "Epoch [81/126], Step [50/55], Loss: 0.2766\n",
      "Epoch [81/126], Train Loss: 0.3203, Train Accuracy: 0.8756\n",
      "Epoch [82/126], Step [10/55], Loss: 0.4263\n",
      "Epoch [82/126], Step [20/55], Loss: 0.3148\n",
      "Epoch [82/126], Step [30/55], Loss: 0.2543\n",
      "Epoch [82/126], Step [40/55], Loss: 0.2704\n",
      "Epoch [82/126], Step [50/55], Loss: 0.3682\n",
      "Epoch [82/126], Train Loss: 0.3222, Train Accuracy: 0.8727\n",
      "Epoch [83/126], Step [10/55], Loss: 0.2773\n",
      "Epoch [83/126], Step [20/55], Loss: 0.1904\n",
      "Epoch [83/126], Step [30/55], Loss: 0.3670\n",
      "Epoch [83/126], Step [40/55], Loss: 0.3867\n",
      "Epoch [83/126], Step [50/55], Loss: 0.2301\n",
      "Epoch [83/126], Train Loss: 0.3247, Train Accuracy: 0.8664\n",
      "Epoch [84/126], Step [10/55], Loss: 0.2535\n",
      "Epoch [84/126], Step [20/55], Loss: 0.3102\n",
      "Epoch [84/126], Step [30/55], Loss: 0.4251\n",
      "Epoch [84/126], Step [40/55], Loss: 0.4709\n",
      "Epoch [84/126], Step [50/55], Loss: 0.2190\n",
      "Epoch [84/126], Train Loss: 0.3234, Train Accuracy: 0.8693\n",
      "Epoch [85/126], Step [10/55], Loss: 0.3572\n",
      "Epoch [85/126], Step [20/55], Loss: 0.3292\n",
      "Epoch [85/126], Step [30/55], Loss: 0.3340\n",
      "Epoch [85/126], Step [40/55], Loss: 0.2625\n",
      "Epoch [85/126], Step [50/55], Loss: 0.1999\n",
      "Epoch [85/126], Train Loss: 0.3194, Train Accuracy: 0.8761\n",
      "Epoch [86/126], Step [10/55], Loss: 0.2842\n",
      "Epoch [86/126], Step [20/55], Loss: 0.3474\n",
      "Epoch [86/126], Step [30/55], Loss: 0.2425\n",
      "Epoch [86/126], Step [40/55], Loss: 0.2291\n",
      "Epoch [86/126], Step [50/55], Loss: 0.3065\n",
      "Epoch [86/126], Train Loss: 0.3197, Train Accuracy: 0.8721\n",
      "Epoch [87/126], Step [10/55], Loss: 0.2524\n",
      "Epoch [87/126], Step [20/55], Loss: 0.6141\n",
      "Epoch [87/126], Step [30/55], Loss: 0.2631\n",
      "Epoch [87/126], Step [40/55], Loss: 0.5150\n",
      "Epoch [87/126], Step [50/55], Loss: 0.2702\n",
      "Epoch [87/126], Train Loss: 0.3195, Train Accuracy: 0.8721\n",
      "Epoch [88/126], Step [10/55], Loss: 0.2264\n",
      "Epoch [88/126], Step [20/55], Loss: 0.3894\n",
      "Epoch [88/126], Step [30/55], Loss: 0.1931\n",
      "Epoch [88/126], Step [40/55], Loss: 0.3281\n",
      "Epoch [88/126], Step [50/55], Loss: 0.4628\n",
      "Epoch [88/126], Train Loss: 0.3188, Train Accuracy: 0.8744\n",
      "Epoch [89/126], Step [10/55], Loss: 0.3753\n",
      "Epoch [89/126], Step [20/55], Loss: 0.1506\n",
      "Epoch [89/126], Step [30/55], Loss: 0.4322\n",
      "Epoch [89/126], Step [40/55], Loss: 0.4690\n",
      "Epoch [89/126], Step [50/55], Loss: 0.2535\n",
      "Epoch [89/126], Train Loss: 0.3257, Train Accuracy: 0.8721\n",
      "Epoch [90/126], Step [10/55], Loss: 0.4438\n",
      "Epoch [90/126], Step [20/55], Loss: 0.3150\n",
      "Epoch [90/126], Step [30/55], Loss: 0.1605\n",
      "Epoch [90/126], Step [40/55], Loss: 0.2664\n",
      "Epoch [90/126], Step [50/55], Loss: 0.3010\n",
      "Epoch [90/126], Train Loss: 0.3179, Train Accuracy: 0.8739\n",
      "Epoch [91/126], Step [10/55], Loss: 0.2921\n",
      "Epoch [91/126], Step [20/55], Loss: 0.1538\n",
      "Epoch [91/126], Step [30/55], Loss: 0.1452\n",
      "Epoch [91/126], Step [40/55], Loss: 0.2737\n",
      "Epoch [91/126], Step [50/55], Loss: 0.2292\n",
      "Epoch [91/126], Train Loss: 0.3211, Train Accuracy: 0.8756\n",
      "Epoch [92/126], Step [10/55], Loss: 0.1842\n",
      "Epoch [92/126], Step [20/55], Loss: 0.1873\n",
      "Epoch [92/126], Step [30/55], Loss: 0.4925\n",
      "Epoch [92/126], Step [40/55], Loss: 0.2177\n",
      "Epoch [92/126], Step [50/55], Loss: 0.2675\n",
      "Epoch [92/126], Train Loss: 0.3140, Train Accuracy: 0.8756\n",
      "Epoch [93/126], Step [10/55], Loss: 0.3360\n",
      "Epoch [93/126], Step [20/55], Loss: 0.4166\n",
      "Epoch [93/126], Step [30/55], Loss: 0.3491\n",
      "Epoch [93/126], Step [40/55], Loss: 0.3144\n",
      "Epoch [93/126], Step [50/55], Loss: 0.2627\n",
      "Epoch [93/126], Train Loss: 0.3178, Train Accuracy: 0.8739\n",
      "Epoch [94/126], Step [10/55], Loss: 0.3418\n",
      "Epoch [94/126], Step [20/55], Loss: 0.1399\n",
      "Epoch [94/126], Step [30/55], Loss: 0.3058\n",
      "Epoch [94/126], Step [40/55], Loss: 0.3776\n",
      "Epoch [94/126], Step [50/55], Loss: 0.4237\n",
      "Epoch [94/126], Train Loss: 0.3180, Train Accuracy: 0.8773\n",
      "Epoch [95/126], Step [10/55], Loss: 0.5048\n",
      "Epoch [95/126], Step [20/55], Loss: 0.3159\n",
      "Epoch [95/126], Step [30/55], Loss: 0.1642\n",
      "Epoch [95/126], Step [40/55], Loss: 0.3616\n",
      "Epoch [95/126], Step [50/55], Loss: 0.3090\n",
      "Epoch [95/126], Train Loss: 0.3155, Train Accuracy: 0.8767\n",
      "Epoch [96/126], Step [10/55], Loss: 0.2868\n",
      "Epoch [96/126], Step [20/55], Loss: 0.3106\n",
      "Epoch [96/126], Step [30/55], Loss: 0.1126\n",
      "Epoch [96/126], Step [40/55], Loss: 0.5389\n",
      "Epoch [96/126], Step [50/55], Loss: 0.2336\n",
      "Epoch [96/126], Train Loss: 0.3175, Train Accuracy: 0.8779\n",
      "Epoch [97/126], Step [10/55], Loss: 0.2071\n",
      "Epoch [97/126], Step [20/55], Loss: 0.3550\n",
      "Epoch [97/126], Step [30/55], Loss: 0.3782\n",
      "Epoch [97/126], Step [40/55], Loss: 0.3107\n",
      "Epoch [97/126], Step [50/55], Loss: 0.2240\n",
      "Epoch [97/126], Train Loss: 0.3160, Train Accuracy: 0.8733\n",
      "Epoch [98/126], Step [10/55], Loss: 0.3160\n",
      "Epoch [98/126], Step [20/55], Loss: 0.4681\n",
      "Epoch [98/126], Step [30/55], Loss: 0.4748\n",
      "Epoch [98/126], Step [40/55], Loss: 0.3026\n",
      "Epoch [98/126], Step [50/55], Loss: 0.3447\n",
      "Epoch [98/126], Train Loss: 0.3236, Train Accuracy: 0.8704\n",
      "Epoch [99/126], Step [10/55], Loss: 0.3959\n",
      "Epoch [99/126], Step [20/55], Loss: 0.3528\n",
      "Epoch [99/126], Step [30/55], Loss: 0.2974\n",
      "Epoch [99/126], Step [40/55], Loss: 0.4821\n",
      "Epoch [99/126], Step [50/55], Loss: 0.5484\n",
      "Epoch [99/126], Train Loss: 0.3177, Train Accuracy: 0.8836\n",
      "Epoch [100/126], Step [10/55], Loss: 0.4197\n",
      "Epoch [100/126], Step [20/55], Loss: 0.2166\n",
      "Epoch [100/126], Step [30/55], Loss: 0.3568\n",
      "Epoch [100/126], Step [40/55], Loss: 0.6572\n",
      "Epoch [100/126], Step [50/55], Loss: 0.5036\n",
      "Epoch [100/126], Train Loss: 0.3238, Train Accuracy: 0.8727\n",
      "Epoch [101/126], Step [10/55], Loss: 0.2012\n",
      "Epoch [101/126], Step [20/55], Loss: 0.3640\n",
      "Epoch [101/126], Step [30/55], Loss: 0.4082\n",
      "Epoch [101/126], Step [40/55], Loss: 0.3320\n",
      "Epoch [101/126], Step [50/55], Loss: 0.3840\n",
      "Epoch [101/126], Train Loss: 0.3297, Train Accuracy: 0.8744\n",
      "Epoch [102/126], Step [10/55], Loss: 0.3356\n",
      "Epoch [102/126], Step [20/55], Loss: 0.5148\n",
      "Epoch [102/126], Step [30/55], Loss: 0.2006\n",
      "Epoch [102/126], Step [40/55], Loss: 0.2857\n",
      "Epoch [102/126], Step [50/55], Loss: 0.3286\n",
      "Epoch [102/126], Train Loss: 0.3200, Train Accuracy: 0.8761\n",
      "Epoch [103/126], Step [10/55], Loss: 0.2319\n",
      "Epoch [103/126], Step [20/55], Loss: 0.3197\n",
      "Epoch [103/126], Step [30/55], Loss: 0.5309\n",
      "Epoch [103/126], Step [40/55], Loss: 0.2532\n",
      "Epoch [103/126], Step [50/55], Loss: 0.2735\n",
      "Epoch [103/126], Train Loss: 0.3142, Train Accuracy: 0.8699\n",
      "Epoch [104/126], Step [10/55], Loss: 0.3231\n",
      "Epoch [104/126], Step [20/55], Loss: 0.2329\n",
      "Epoch [104/126], Step [30/55], Loss: 0.3987\n",
      "Epoch [104/126], Step [40/55], Loss: 0.1927\n",
      "Epoch [104/126], Step [50/55], Loss: 0.2933\n",
      "Epoch [104/126], Train Loss: 0.3247, Train Accuracy: 0.8756\n",
      "Epoch [105/126], Step [10/55], Loss: 0.2880\n",
      "Epoch [105/126], Step [20/55], Loss: 0.1231\n",
      "Epoch [105/126], Step [30/55], Loss: 0.5523\n",
      "Epoch [105/126], Step [40/55], Loss: 0.2190\n",
      "Epoch [105/126], Step [50/55], Loss: 0.2128\n",
      "Epoch [105/126], Train Loss: 0.3201, Train Accuracy: 0.8733\n",
      "Epoch [106/126], Step [10/55], Loss: 0.2258\n",
      "Epoch [106/126], Step [20/55], Loss: 0.3019\n",
      "Epoch [106/126], Step [30/55], Loss: 0.6076\n",
      "Epoch [106/126], Step [40/55], Loss: 0.4434\n",
      "Epoch [106/126], Step [50/55], Loss: 0.5152\n",
      "Epoch [106/126], Train Loss: 0.3197, Train Accuracy: 0.8739\n",
      "Epoch [107/126], Step [10/55], Loss: 0.2152\n",
      "Epoch [107/126], Step [20/55], Loss: 0.3912\n",
      "Epoch [107/126], Step [30/55], Loss: 0.3291\n",
      "Epoch [107/126], Step [40/55], Loss: 0.2153\n",
      "Epoch [107/126], Step [50/55], Loss: 0.3620\n",
      "Epoch [107/126], Train Loss: 0.3165, Train Accuracy: 0.8704\n",
      "Epoch [108/126], Step [10/55], Loss: 0.4389\n",
      "Epoch [108/126], Step [20/55], Loss: 0.4610\n",
      "Epoch [108/126], Step [30/55], Loss: 0.2375\n",
      "Epoch [108/126], Step [40/55], Loss: 0.3358\n",
      "Epoch [108/126], Step [50/55], Loss: 0.3410\n",
      "Epoch [108/126], Train Loss: 0.3240, Train Accuracy: 0.8699\n",
      "Epoch [109/126], Step [10/55], Loss: 0.2163\n",
      "Epoch [109/126], Step [20/55], Loss: 0.2258\n",
      "Epoch [109/126], Step [30/55], Loss: 0.1360\n",
      "Epoch [109/126], Step [40/55], Loss: 0.3625\n",
      "Epoch [109/126], Step [50/55], Loss: 0.3167\n",
      "Epoch [109/126], Train Loss: 0.3197, Train Accuracy: 0.8733\n",
      "Epoch [110/126], Step [10/55], Loss: 0.4567\n",
      "Epoch [110/126], Step [20/55], Loss: 0.3223\n",
      "Epoch [110/126], Step [30/55], Loss: 0.3132\n",
      "Epoch [110/126], Step [40/55], Loss: 0.4033\n",
      "Epoch [110/126], Step [50/55], Loss: 0.3111\n",
      "Epoch [110/126], Train Loss: 0.3199, Train Accuracy: 0.8733\n",
      "Epoch [111/126], Step [10/55], Loss: 0.2194\n",
      "Epoch [111/126], Step [20/55], Loss: 0.1677\n",
      "Epoch [111/126], Step [30/55], Loss: 0.3334\n",
      "Epoch [111/126], Step [40/55], Loss: 0.2504\n",
      "Epoch [111/126], Step [50/55], Loss: 0.3823\n",
      "Epoch [111/126], Train Loss: 0.3198, Train Accuracy: 0.8779\n",
      "Epoch [112/126], Step [10/55], Loss: 0.4561\n",
      "Epoch [112/126], Step [20/55], Loss: 0.5405\n",
      "Epoch [112/126], Step [30/55], Loss: 0.2790\n",
      "Epoch [112/126], Step [40/55], Loss: 0.2075\n",
      "Epoch [112/126], Step [50/55], Loss: 0.4794\n",
      "Epoch [112/126], Train Loss: 0.3162, Train Accuracy: 0.8744\n",
      "Epoch [113/126], Step [10/55], Loss: 0.4725\n",
      "Epoch [113/126], Step [20/55], Loss: 0.3117\n",
      "Epoch [113/126], Step [30/55], Loss: 0.1474\n",
      "Epoch [113/126], Step [40/55], Loss: 0.1863\n",
      "Epoch [113/126], Step [50/55], Loss: 0.3735\n",
      "Epoch [113/126], Train Loss: 0.3167, Train Accuracy: 0.8727\n",
      "Epoch [114/126], Step [10/55], Loss: 0.2974\n",
      "Epoch [114/126], Step [20/55], Loss: 0.3893\n",
      "Epoch [114/126], Step [30/55], Loss: 0.1010\n",
      "Epoch [114/126], Step [40/55], Loss: 0.2746\n",
      "Epoch [114/126], Step [50/55], Loss: 0.3444\n",
      "Epoch [114/126], Train Loss: 0.3190, Train Accuracy: 0.8750\n",
      "Epoch [115/126], Step [10/55], Loss: 0.4417\n",
      "Epoch [115/126], Step [20/55], Loss: 0.2633\n",
      "Epoch [115/126], Step [30/55], Loss: 0.3402\n",
      "Epoch [115/126], Step [40/55], Loss: 0.4659\n",
      "Epoch [115/126], Step [50/55], Loss: 0.2336\n",
      "Epoch [115/126], Train Loss: 0.3155, Train Accuracy: 0.8779\n",
      "Epoch [116/126], Step [10/55], Loss: 0.2559\n",
      "Epoch [116/126], Step [20/55], Loss: 0.3861\n",
      "Epoch [116/126], Step [30/55], Loss: 0.2716\n",
      "Epoch [116/126], Step [40/55], Loss: 0.2292\n",
      "Epoch [116/126], Step [50/55], Loss: 0.4214\n",
      "Epoch [116/126], Train Loss: 0.3103, Train Accuracy: 0.8739\n",
      "Epoch [117/126], Step [10/55], Loss: 0.5473\n",
      "Epoch [117/126], Step [20/55], Loss: 0.2873\n",
      "Epoch [117/126], Step [30/55], Loss: 0.1410\n",
      "Epoch [117/126], Step [40/55], Loss: 0.2322\n",
      "Epoch [117/126], Step [50/55], Loss: 0.5019\n",
      "Epoch [117/126], Train Loss: 0.3173, Train Accuracy: 0.8682\n",
      "Epoch [118/126], Step [10/55], Loss: 0.4483\n",
      "Epoch [118/126], Step [20/55], Loss: 0.3703\n",
      "Epoch [118/126], Step [30/55], Loss: 0.3571\n",
      "Epoch [118/126], Step [40/55], Loss: 0.1708\n",
      "Epoch [118/126], Step [50/55], Loss: 0.3073\n",
      "Epoch [118/126], Train Loss: 0.3173, Train Accuracy: 0.8790\n",
      "Epoch [119/126], Step [10/55], Loss: 0.1369\n",
      "Epoch [119/126], Step [20/55], Loss: 0.4874\n",
      "Epoch [119/126], Step [30/55], Loss: 0.1369\n",
      "Epoch [119/126], Step [40/55], Loss: 0.3483\n",
      "Epoch [119/126], Step [50/55], Loss: 0.6114\n",
      "Epoch [119/126], Train Loss: 0.3187, Train Accuracy: 0.8750\n",
      "Epoch [120/126], Step [10/55], Loss: 0.2988\n",
      "Epoch [120/126], Step [20/55], Loss: 0.3611\n",
      "Epoch [120/126], Step [30/55], Loss: 0.5025\n",
      "Epoch [120/126], Step [40/55], Loss: 0.1703\n",
      "Epoch [120/126], Step [50/55], Loss: 0.3141\n",
      "Epoch [120/126], Train Loss: 0.3199, Train Accuracy: 0.8744\n",
      "Epoch [121/126], Step [10/55], Loss: 0.1575\n",
      "Epoch [121/126], Step [20/55], Loss: 0.1759\n",
      "Epoch [121/126], Step [30/55], Loss: 0.3127\n",
      "Epoch [121/126], Step [40/55], Loss: 0.4116\n",
      "Epoch [121/126], Step [50/55], Loss: 0.2640\n",
      "Epoch [121/126], Train Loss: 0.3215, Train Accuracy: 0.8767\n",
      "Epoch [122/126], Step [10/55], Loss: 0.2647\n",
      "Epoch [122/126], Step [20/55], Loss: 0.1845\n",
      "Epoch [122/126], Step [30/55], Loss: 0.3142\n",
      "Epoch [122/126], Step [40/55], Loss: 0.3295\n",
      "Epoch [122/126], Step [50/55], Loss: 0.3629\n",
      "Epoch [122/126], Train Loss: 0.3155, Train Accuracy: 0.8693\n",
      "Epoch [123/126], Step [10/55], Loss: 0.1938\n",
      "Epoch [123/126], Step [20/55], Loss: 0.3838\n",
      "Epoch [123/126], Step [30/55], Loss: 0.2151\n",
      "Epoch [123/126], Step [40/55], Loss: 0.4572\n",
      "Epoch [123/126], Step [50/55], Loss: 0.2675\n",
      "Epoch [123/126], Train Loss: 0.3177, Train Accuracy: 0.8761\n",
      "Epoch [124/126], Step [10/55], Loss: 0.4438\n",
      "Epoch [124/126], Step [20/55], Loss: 0.2354\n",
      "Epoch [124/126], Step [30/55], Loss: 0.2363\n",
      "Epoch [124/126], Step [40/55], Loss: 0.3311\n",
      "Epoch [124/126], Step [50/55], Loss: 0.3424\n",
      "Epoch [124/126], Train Loss: 0.3215, Train Accuracy: 0.8727\n",
      "Epoch [125/126], Step [10/55], Loss: 0.3152\n",
      "Epoch [125/126], Step [20/55], Loss: 0.2202\n",
      "Epoch [125/126], Step [30/55], Loss: 0.2185\n",
      "Epoch [125/126], Step [40/55], Loss: 0.3039\n",
      "Epoch [125/126], Step [50/55], Loss: 0.3712\n",
      "Epoch [125/126], Train Loss: 0.3212, Train Accuracy: 0.8733\n",
      "Epoch [126/126], Step [10/55], Loss: 0.1911\n",
      "Epoch [126/126], Step [20/55], Loss: 0.1696\n",
      "Epoch [126/126], Step [30/55], Loss: 0.3365\n",
      "Epoch [126/126], Step [40/55], Loss: 0.5823\n",
      "Epoch [126/126], Step [50/55], Loss: 0.4053\n",
      "Epoch [126/126], Train Loss: 0.3148, Train Accuracy: 0.8767\n",
      "Test AUC: 0.8646\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_size = mlp_tr.shape[1]\n",
    "hidden_size = best_params_mlp['hidden_size']\n",
    "\n",
    "model_mlp = MLP(input_size, hidden_size=best_params_mlp['hidden_size'], dropout_rate= best_params_mlp['dropout_rate'])\n",
    "\n",
    "X_train = torch.tensor(X_train.to_numpy(), dtype=torch.float32)\n",
    "X_val = torch.tensor(X_val.to_numpy(), dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.to_numpy(), dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val.to_numpy(), dtype=torch.float32)\n",
    "\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=best_params_mlp['batch_size'], shuffle=True)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model_mlp.parameters(), lr=best_params_mlp['lr'])\n",
    "\n",
    "num_epochs = best_params_mlp['num_epochs']\n",
    "batch_size = best_params_mlp['batch_size']\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        outputs = model_mlp(inputs)\n",
    "        loss = criterion(outputs, labels.unsqueeze(1)) \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model_mlp.parameters(), max_norm=1.0) \n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()  \n",
    "        predicted = (outputs > 0.5).float() \n",
    "        correct_predictions += (predicted == labels.unsqueeze(1)).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                  .format(epoch + 1, num_epochs, i + 1, len(train_loader), loss.item()))\n",
    "\n",
    "    epoch_loss /= len(train_loader)\n",
    "    epoch_accuracy = correct_predictions / total_samples\n",
    "\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracies.append(epoch_accuracy)\n",
    "\n",
    "    print('Epoch [{}/{}], Train Loss: {:.4f}, Train Accuracy: {:.4f}'\n",
    "          .format(epoch + 1, num_epochs, epoch_loss, epoch_accuracy))\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model_mlp(X_val)\n",
    "    predicted_probs = outputs.cpu().numpy()\n",
    "    \n",
    "    auc = roc_auc_score(y_val.cpu().numpy(), predicted_probs) \n",
    "    print('Test AUC: {:.4f}'.format(auc))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_accuracies, label='Train Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0753186",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T12:52:38.617377Z",
     "iopub.status.busy": "2025-03-15T12:52:38.616745Z",
     "iopub.status.idle": "2025-03-15T12:52:38.630532Z",
     "shell.execute_reply": "2025-03-15T12:52:38.629113Z"
    },
    "papermill": {
     "duration": 0.037592,
     "end_time": "2025-03-15T12:52:38.632569",
     "exception": false,
     "start_time": "2025-03-15T12:52:38.594977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The models state dictionary has been saved.: /kaggle/working/mlp_model_state.pth\n",
      "The model's state dictionary has been loaded.: /kaggle/working/mlp_model_state.pth\n"
     ]
    }
   ],
   "source": [
    "PATH = \"/kaggle/working/mlp_model_state.pth\"\n",
    "torch.save(model_mlp.state_dict(), PATH)\n",
    "print('The models state dictionary has been saved.: {}'.format(PATH))\n",
    "\n",
    "model_mlp_pred = MLP(input_size, hidden_size)\n",
    "model_mlp_pred.load_state_dict(torch.load(PATH))\n",
    "model_mlp_pred.eval()  \n",
    "print(\"The model's state dictionary has been loaded.: {}\".format(PATH))\n",
    "\n",
    "test_tensor = torch.tensor(mlp_te.to_numpy(), dtype=torch.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model_mlp_pred(test_tensor)\n",
    "    predicted_probs_mlp = outputs.cpu().numpy()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0670b285",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T12:52:38.672897Z",
     "iopub.status.busy": "2025-03-15T12:52:38.672522Z",
     "iopub.status.idle": "2025-03-15T12:52:38.677569Z",
     "shell.execute_reply": "2025-03-15T12:52:38.676332Z"
    },
    "papermill": {
     "duration": 0.02727,
     "end_time": "2025-03-15T12:52:38.679423",
     "exception": false,
     "start_time": "2025-03-15T12:52:38.652153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sum_pred(pred_1, pred_2):\n",
    "    return (pred_1 + pred_2) / 2\n",
    "\n",
    "def sum_pred_2(pred_1, pred_2, pred_3):\n",
    "    return (pred_1 + pred_2 + pred_3) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af1c80b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T12:52:38.719589Z",
     "iopub.status.busy": "2025-03-15T12:52:38.719201Z",
     "iopub.status.idle": "2025-03-15T12:52:38.759596Z",
     "shell.execute_reply": "2025-03-15T12:52:38.758453Z"
    },
    "papermill": {
     "duration": 0.063154,
     "end_time": "2025-03-15T12:52:38.761592",
     "exception": false,
     "start_time": "2025-03-15T12:52:38.698438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_1 = sum_pred(predicted_probs_mlp, probabilities_lin)\n",
    "sub_2 = sum_pred(probabilities_cat, probabilities_lin)\n",
    "sub_3 = sum_pred_2(predicted_probs_mlp, probabilities_lin, probabilities_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88311751",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T12:52:38.865544Z",
     "iopub.status.busy": "2025-03-15T12:52:38.865061Z",
     "iopub.status.idle": "2025-03-15T12:52:38.888321Z",
     "shell.execute_reply": "2025-03-15T12:52:38.887269Z"
    },
    "papermill": {
     "duration": 0.10932,
     "end_time": "2025-03-15T12:52:38.890010",
     "exception": false,
     "start_time": "2025-03-15T12:52:38.780690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rainfall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2190</td>\n",
       "      <td>0.980159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2191</td>\n",
       "      <td>0.982818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2192</td>\n",
       "      <td>0.979244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2193</td>\n",
       "      <td>0.654192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2194</td>\n",
       "      <td>0.654057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>2915</td>\n",
       "      <td>0.976426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>2916</td>\n",
       "      <td>0.908593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>2917</td>\n",
       "      <td>0.972141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>2918</td>\n",
       "      <td>0.982242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>2919</td>\n",
       "      <td>0.960638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>730 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  rainfall\n",
       "0    2190  0.980159\n",
       "1    2191  0.982818\n",
       "2    2192  0.979244\n",
       "3    2193  0.654192\n",
       "4    2194  0.654057\n",
       "..    ...       ...\n",
       "725  2915  0.976426\n",
       "726  2916  0.908593\n",
       "727  2917  0.972141\n",
       "728  2918  0.982242\n",
       "729  2919  0.960638\n",
       "\n",
       "[730 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pd.DataFrame({\n",
    "    'id': df_test_id, \n",
    "    'rainfall': sub_3[:,0]\n",
    "})\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70fa6646",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T12:52:38.932250Z",
     "iopub.status.busy": "2025-03-15T12:52:38.931823Z",
     "iopub.status.idle": "2025-03-15T12:52:38.937487Z",
     "shell.execute_reply": "2025-03-15T12:52:38.936474Z"
    },
    "papermill": {
     "duration": 0.02947,
     "end_time": "2025-03-15T12:52:38.939444",
     "exception": false,
     "start_time": "2025-03-15T12:52:38.909974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\noutput = pd.DataFrame({\\n    'id': df_test_id, \\n    'rainfall': sub_2[:,0]\\n})\\n\\noutput\\n\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "output = pd.DataFrame({\n",
    "    'id': df_test_id, \n",
    "    'rainfall': sub_2[:,0]\n",
    "})\n",
    "\n",
    "output\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "125837f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T12:52:38.981051Z",
     "iopub.status.busy": "2025-03-15T12:52:38.980605Z",
     "iopub.status.idle": "2025-03-15T12:52:38.986511Z",
     "shell.execute_reply": "2025-03-15T12:52:38.985460Z"
    },
    "papermill": {
     "duration": 0.028808,
     "end_time": "2025-03-15T12:52:38.988231",
     "exception": false,
     "start_time": "2025-03-15T12:52:38.959423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\noutput = pd.DataFrame({\\n    'id': df_test_id, \\n    'rainfall': sub_3[:,0]\\n})\\n\\noutput\\n\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "output = pd.DataFrame({\n",
    "    'id': df_test_id, \n",
    "    'rainfall': sub_3[:,0]\n",
    "})\n",
    "\n",
    "output\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2221236",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T12:52:39.030287Z",
     "iopub.status.busy": "2025-03-15T12:52:39.029731Z",
     "iopub.status.idle": "2025-03-15T12:52:39.044318Z",
     "shell.execute_reply": "2025-03-15T12:52:39.042840Z"
    },
    "papermill": {
     "duration": 0.038425,
     "end_time": "2025-03-15T12:52:39.046374",
     "exception": false,
     "start_time": "2025-03-15T12:52:39.007949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "output.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11251744,
     "sourceId": 91714,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4168.416616,
   "end_time": "2025-03-15T12:52:41.196807",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-15T11:43:12.780191",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
